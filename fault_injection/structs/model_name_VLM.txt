: PrismaticVLM(
  (vision_backbone): DinoSigLIPViTBackbone(
    (dino_featurizer): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))
        (norm): Identity()
      )
      (pos_drop): Dropout(p=0.0, inplace=False)
      (patch_drop): Identity()
      (norm_pre): Identity()
      (blocks): Sequential(
        (0): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (1): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (2): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (3): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (4): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (5): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (6): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (7): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (8): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (9): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (10): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (11): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (12): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (13): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (14): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (15): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (16): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (17): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (18): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (19): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (20): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (21): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (22): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
        (23): Block(
          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1024, out_features=3072, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1024, out_features=1024, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): LayerScale()
          (drop_path1): Identity()
          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1024, out_features=4096, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4096, out_features=1024, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): LayerScale()
          (drop_path2): Identity()
        )
      )
      (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (fc_norm): Identity()
      (head_drop): Dropout(p=0.0, inplace=False)
      (head): Identity()
    )
    (siglip_featurizer): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14))
        (norm): Identity()
      )
      (pos_drop): Dropout(p=0.0, inplace=False)
      (patch_drop): Identity()
      (norm_pre): Identity()
      (blocks): Sequential(
        (0): Block(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1152, out_features=4304, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4304, out_features=1152, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (1): Block(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1152, out_features=4304, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4304, out_features=1152, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (2): Block(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1152, out_features=4304, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4304, out_features=1152, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (3): Block(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1152, out_features=4304, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4304, out_features=1152, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (4): Block(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1152, out_features=4304, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4304, out_features=1152, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (5): Block(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1152, out_features=4304, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4304, out_features=1152, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (6): Block(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1152, out_features=4304, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4304, out_features=1152, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (7): Block(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1152, out_features=4304, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4304, out_features=1152, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (8): Block(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1152, out_features=4304, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4304, out_features=1152, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (9): Block(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1152, out_features=4304, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4304, out_features=1152, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (10): Block(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1152, out_features=4304, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4304, out_features=1152, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (11): Block(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1152, out_features=4304, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4304, out_features=1152, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (12): Block(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1152, out_features=4304, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4304, out_features=1152, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (13): Block(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1152, out_features=4304, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4304, out_features=1152, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (14): Block(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1152, out_features=4304, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4304, out_features=1152, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (15): Block(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1152, out_features=4304, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4304, out_features=1152, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (16): Block(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1152, out_features=4304, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4304, out_features=1152, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (17): Block(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1152, out_features=4304, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4304, out_features=1152, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (18): Block(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1152, out_features=4304, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4304, out_features=1152, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (19): Block(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1152, out_features=4304, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4304, out_features=1152, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (20): Block(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1152, out_features=4304, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4304, out_features=1152, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (21): Block(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1152, out_features=4304, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4304, out_features=1152, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (22): Block(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1152, out_features=4304, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4304, out_features=1152, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (23): Block(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1152, out_features=4304, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4304, out_features=1152, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (24): Block(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1152, out_features=4304, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4304, out_features=1152, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (25): Block(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1152, out_features=4304, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4304, out_features=1152, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
        (26): Block(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (q_norm): Identity()
            (k_norm): Identity()
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (ls1): Identity()
          (drop_path1): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1152, out_features=4304, bias=True)
            (act): GELU(approximate='none')
            (drop1): Dropout(p=0.0, inplace=False)
            (norm): Identity()
            (fc2): Linear(in_features=4304, out_features=1152, bias=True)
            (drop2): Dropout(p=0.0, inplace=False)
          )
          (ls2): Identity()
          (drop_path2): Identity()
        )
      )
      (norm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (attn_pool): AttentionPoolLatent(
        (q): Linear(in_features=1152, out_features=1152, bias=True)
        (kv): Linear(in_features=1152, out_features=2304, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (proj): Linear(in_features=1152, out_features=1152, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (norm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1152, out_features=4304, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4304, out_features=1152, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
      )
      (fc_norm): Identity()
      (head_drop): Dropout(p=0.0, inplace=False)
      (head): Identity()
    )
  )
  (llm_backbone): LLaMa2LLMBackbone(
    (llm): LlamaForCausalLM(
      (model): LlamaModel(
        (embed_tokens): Embedding(32064, 4096)
        (layers): ModuleList(
          (0-31): 32 x LlamaDecoderLayer(
            (self_attn): LlamaSdpaAttention(
              (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
              (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
              (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
              (rotary_emb): LlamaRotaryEmbedding()
            )
            (mlp): LlamaMLP(
              (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
              (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
              (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
              (act_fn): SiLU()
            )
            (input_layernorm): LlamaRMSNorm()
            (post_attention_layernorm): LlamaRMSNorm()
          )
        )
        (norm): LlamaRMSNorm()
      )
      (lm_head): Linear(in_features=4096, out_features=32064, bias=False)
    )
  )
  (projector): FusedMLPProjector(
    (projector): Sequential(
      (0): Linear(in_features=2176, out_features=8704, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=8704, out_features=4096, bias=True)
      (3): GELU(approximate='none')
      (4): Linear(in_features=4096, out_features=4096, bias=True)
    )
  )
)
vision_backbone: DinoSigLIPViTBackbone(
  (dino_featurizer): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))
      (norm): Identity()
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (patch_drop): Identity()
    (norm_pre): Identity()
    (blocks): Sequential(
      (0): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): LayerScale()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): LayerScale()
        (drop_path2): Identity()
      )
      (1): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): LayerScale()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): LayerScale()
        (drop_path2): Identity()
      )
      (2): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): LayerScale()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): LayerScale()
        (drop_path2): Identity()
      )
      (3): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): LayerScale()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): LayerScale()
        (drop_path2): Identity()
      )
      (4): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): LayerScale()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): LayerScale()
        (drop_path2): Identity()
      )
      (5): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): LayerScale()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): LayerScale()
        (drop_path2): Identity()
      )
      (6): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): LayerScale()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): LayerScale()
        (drop_path2): Identity()
      )
      (7): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): LayerScale()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): LayerScale()
        (drop_path2): Identity()
      )
      (8): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): LayerScale()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): LayerScale()
        (drop_path2): Identity()
      )
      (9): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): LayerScale()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): LayerScale()
        (drop_path2): Identity()
      )
      (10): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): LayerScale()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): LayerScale()
        (drop_path2): Identity()
      )
      (11): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): LayerScale()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): LayerScale()
        (drop_path2): Identity()
      )
      (12): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): LayerScale()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): LayerScale()
        (drop_path2): Identity()
      )
      (13): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): LayerScale()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): LayerScale()
        (drop_path2): Identity()
      )
      (14): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): LayerScale()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): LayerScale()
        (drop_path2): Identity()
      )
      (15): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): LayerScale()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): LayerScale()
        (drop_path2): Identity()
      )
      (16): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): LayerScale()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): LayerScale()
        (drop_path2): Identity()
      )
      (17): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): LayerScale()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): LayerScale()
        (drop_path2): Identity()
      )
      (18): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): LayerScale()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): LayerScale()
        (drop_path2): Identity()
      )
      (19): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): LayerScale()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): LayerScale()
        (drop_path2): Identity()
      )
      (20): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): LayerScale()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): LayerScale()
        (drop_path2): Identity()
      )
      (21): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): LayerScale()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): LayerScale()
        (drop_path2): Identity()
      )
      (22): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): LayerScale()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): LayerScale()
        (drop_path2): Identity()
      )
      (23): Block(
        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1024, out_features=3072, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1024, out_features=1024, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): LayerScale()
        (drop_path1): Identity()
        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1024, out_features=4096, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4096, out_features=1024, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): LayerScale()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (fc_norm): Identity()
    (head_drop): Dropout(p=0.0, inplace=False)
    (head): Identity()
  )
  (siglip_featurizer): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14))
      (norm): Identity()
    )
    (pos_drop): Dropout(p=0.0, inplace=False)
    (patch_drop): Identity()
    (norm_pre): Identity()
    (blocks): Sequential(
      (0): Block(
        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1152, out_features=3456, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1152, out_features=1152, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1152, out_features=4304, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4304, out_features=1152, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (1): Block(
        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1152, out_features=3456, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1152, out_features=1152, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1152, out_features=4304, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4304, out_features=1152, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (2): Block(
        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1152, out_features=3456, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1152, out_features=1152, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1152, out_features=4304, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4304, out_features=1152, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (3): Block(
        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1152, out_features=3456, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1152, out_features=1152, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1152, out_features=4304, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4304, out_features=1152, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (4): Block(
        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1152, out_features=3456, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1152, out_features=1152, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1152, out_features=4304, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4304, out_features=1152, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (5): Block(
        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1152, out_features=3456, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1152, out_features=1152, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1152, out_features=4304, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4304, out_features=1152, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (6): Block(
        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1152, out_features=3456, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1152, out_features=1152, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1152, out_features=4304, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4304, out_features=1152, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (7): Block(
        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1152, out_features=3456, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1152, out_features=1152, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1152, out_features=4304, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4304, out_features=1152, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (8): Block(
        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1152, out_features=3456, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1152, out_features=1152, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1152, out_features=4304, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4304, out_features=1152, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (9): Block(
        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1152, out_features=3456, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1152, out_features=1152, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1152, out_features=4304, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4304, out_features=1152, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (10): Block(
        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1152, out_features=3456, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1152, out_features=1152, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1152, out_features=4304, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4304, out_features=1152, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (11): Block(
        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1152, out_features=3456, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1152, out_features=1152, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1152, out_features=4304, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4304, out_features=1152, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (12): Block(
        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1152, out_features=3456, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1152, out_features=1152, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1152, out_features=4304, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4304, out_features=1152, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (13): Block(
        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1152, out_features=3456, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1152, out_features=1152, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1152, out_features=4304, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4304, out_features=1152, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (14): Block(
        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1152, out_features=3456, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1152, out_features=1152, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1152, out_features=4304, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4304, out_features=1152, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (15): Block(
        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1152, out_features=3456, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1152, out_features=1152, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1152, out_features=4304, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4304, out_features=1152, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (16): Block(
        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1152, out_features=3456, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1152, out_features=1152, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1152, out_features=4304, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4304, out_features=1152, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (17): Block(
        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1152, out_features=3456, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1152, out_features=1152, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1152, out_features=4304, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4304, out_features=1152, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (18): Block(
        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1152, out_features=3456, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1152, out_features=1152, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1152, out_features=4304, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4304, out_features=1152, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (19): Block(
        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1152, out_features=3456, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1152, out_features=1152, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1152, out_features=4304, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4304, out_features=1152, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (20): Block(
        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1152, out_features=3456, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1152, out_features=1152, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1152, out_features=4304, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4304, out_features=1152, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (21): Block(
        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1152, out_features=3456, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1152, out_features=1152, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1152, out_features=4304, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4304, out_features=1152, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (22): Block(
        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1152, out_features=3456, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1152, out_features=1152, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1152, out_features=4304, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4304, out_features=1152, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (23): Block(
        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1152, out_features=3456, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1152, out_features=1152, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1152, out_features=4304, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4304, out_features=1152, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (24): Block(
        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1152, out_features=3456, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1152, out_features=1152, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1152, out_features=4304, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4304, out_features=1152, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (25): Block(
        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1152, out_features=3456, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1152, out_features=1152, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1152, out_features=4304, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4304, out_features=1152, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
      (26): Block(
        (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1152, out_features=3456, bias=True)
          (q_norm): Identity()
          (k_norm): Identity()
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1152, out_features=1152, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (ls1): Identity()
        (drop_path1): Identity()
        (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=1152, out_features=4304, bias=True)
          (act): GELU(approximate='none')
          (drop1): Dropout(p=0.0, inplace=False)
          (norm): Identity()
          (fc2): Linear(in_features=4304, out_features=1152, bias=True)
          (drop2): Dropout(p=0.0, inplace=False)
        )
        (ls2): Identity()
        (drop_path2): Identity()
      )
    )
    (norm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (attn_pool): AttentionPoolLatent(
      (q): Linear(in_features=1152, out_features=1152, bias=True)
      (kv): Linear(in_features=1152, out_features=2304, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (proj): Linear(in_features=1152, out_features=1152, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
      (norm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1152, out_features=4304, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4304, out_features=1152, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
    )
    (fc_norm): Identity()
    (head_drop): Dropout(p=0.0, inplace=False)
    (head): Identity()
  )
)
vision_backbone.dino_featurizer: VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))
    (norm): Identity()
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (patch_drop): Identity()
  (norm_pre): Identity()
  (blocks): Sequential(
    (0): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): LayerScale()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): LayerScale()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): LayerScale()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): LayerScale()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): LayerScale()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): LayerScale()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): LayerScale()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): LayerScale()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): LayerScale()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): LayerScale()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): LayerScale()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): LayerScale()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): LayerScale()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): LayerScale()
      (drop_path2): Identity()
    )
    (7): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): LayerScale()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): LayerScale()
      (drop_path2): Identity()
    )
    (8): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): LayerScale()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): LayerScale()
      (drop_path2): Identity()
    )
    (9): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): LayerScale()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): LayerScale()
      (drop_path2): Identity()
    )
    (10): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): LayerScale()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): LayerScale()
      (drop_path2): Identity()
    )
    (11): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): LayerScale()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): LayerScale()
      (drop_path2): Identity()
    )
    (12): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): LayerScale()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): LayerScale()
      (drop_path2): Identity()
    )
    (13): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): LayerScale()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): LayerScale()
      (drop_path2): Identity()
    )
    (14): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): LayerScale()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): LayerScale()
      (drop_path2): Identity()
    )
    (15): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): LayerScale()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): LayerScale()
      (drop_path2): Identity()
    )
    (16): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): LayerScale()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): LayerScale()
      (drop_path2): Identity()
    )
    (17): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): LayerScale()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): LayerScale()
      (drop_path2): Identity()
    )
    (18): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): LayerScale()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): LayerScale()
      (drop_path2): Identity()
    )
    (19): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): LayerScale()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): LayerScale()
      (drop_path2): Identity()
    )
    (20): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): LayerScale()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): LayerScale()
      (drop_path2): Identity()
    )
    (21): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): LayerScale()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): LayerScale()
      (drop_path2): Identity()
    )
    (22): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): LayerScale()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): LayerScale()
      (drop_path2): Identity()
    )
    (23): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): LayerScale()
      (drop_path1): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): LayerScale()
      (drop_path2): Identity()
    )
  )
  (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (fc_norm): Identity()
  (head_drop): Dropout(p=0.0, inplace=False)
  (head): Identity()
)
vision_backbone.dino_featurizer.patch_embed: PatchEmbed(
  (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))
  (norm): Identity()
)
vision_backbone.dino_featurizer.patch_embed.proj: Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))
vision_backbone.dino_featurizer.patch_embed.norm: Identity()
vision_backbone.dino_featurizer.pos_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.patch_drop: Identity()
vision_backbone.dino_featurizer.norm_pre: Identity()
vision_backbone.dino_featurizer.blocks: Sequential(
  (0): Block(
    (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1024, out_features=3072, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1024, out_features=1024, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): LayerScale()
    (drop_path1): Identity()
    (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): LayerScale()
    (drop_path2): Identity()
  )
  (1): Block(
    (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1024, out_features=3072, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1024, out_features=1024, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): LayerScale()
    (drop_path1): Identity()
    (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): LayerScale()
    (drop_path2): Identity()
  )
  (2): Block(
    (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1024, out_features=3072, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1024, out_features=1024, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): LayerScale()
    (drop_path1): Identity()
    (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): LayerScale()
    (drop_path2): Identity()
  )
  (3): Block(
    (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1024, out_features=3072, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1024, out_features=1024, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): LayerScale()
    (drop_path1): Identity()
    (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): LayerScale()
    (drop_path2): Identity()
  )
  (4): Block(
    (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1024, out_features=3072, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1024, out_features=1024, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): LayerScale()
    (drop_path1): Identity()
    (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): LayerScale()
    (drop_path2): Identity()
  )
  (5): Block(
    (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1024, out_features=3072, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1024, out_features=1024, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): LayerScale()
    (drop_path1): Identity()
    (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): LayerScale()
    (drop_path2): Identity()
  )
  (6): Block(
    (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1024, out_features=3072, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1024, out_features=1024, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): LayerScale()
    (drop_path1): Identity()
    (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): LayerScale()
    (drop_path2): Identity()
  )
  (7): Block(
    (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1024, out_features=3072, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1024, out_features=1024, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): LayerScale()
    (drop_path1): Identity()
    (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): LayerScale()
    (drop_path2): Identity()
  )
  (8): Block(
    (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1024, out_features=3072, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1024, out_features=1024, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): LayerScale()
    (drop_path1): Identity()
    (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): LayerScale()
    (drop_path2): Identity()
  )
  (9): Block(
    (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1024, out_features=3072, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1024, out_features=1024, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): LayerScale()
    (drop_path1): Identity()
    (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): LayerScale()
    (drop_path2): Identity()
  )
  (10): Block(
    (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1024, out_features=3072, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1024, out_features=1024, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): LayerScale()
    (drop_path1): Identity()
    (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): LayerScale()
    (drop_path2): Identity()
  )
  (11): Block(
    (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1024, out_features=3072, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1024, out_features=1024, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): LayerScale()
    (drop_path1): Identity()
    (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): LayerScale()
    (drop_path2): Identity()
  )
  (12): Block(
    (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1024, out_features=3072, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1024, out_features=1024, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): LayerScale()
    (drop_path1): Identity()
    (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): LayerScale()
    (drop_path2): Identity()
  )
  (13): Block(
    (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1024, out_features=3072, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1024, out_features=1024, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): LayerScale()
    (drop_path1): Identity()
    (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): LayerScale()
    (drop_path2): Identity()
  )
  (14): Block(
    (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1024, out_features=3072, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1024, out_features=1024, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): LayerScale()
    (drop_path1): Identity()
    (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): LayerScale()
    (drop_path2): Identity()
  )
  (15): Block(
    (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1024, out_features=3072, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1024, out_features=1024, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): LayerScale()
    (drop_path1): Identity()
    (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): LayerScale()
    (drop_path2): Identity()
  )
  (16): Block(
    (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1024, out_features=3072, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1024, out_features=1024, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): LayerScale()
    (drop_path1): Identity()
    (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): LayerScale()
    (drop_path2): Identity()
  )
  (17): Block(
    (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1024, out_features=3072, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1024, out_features=1024, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): LayerScale()
    (drop_path1): Identity()
    (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): LayerScale()
    (drop_path2): Identity()
  )
  (18): Block(
    (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1024, out_features=3072, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1024, out_features=1024, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): LayerScale()
    (drop_path1): Identity()
    (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): LayerScale()
    (drop_path2): Identity()
  )
  (19): Block(
    (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1024, out_features=3072, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1024, out_features=1024, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): LayerScale()
    (drop_path1): Identity()
    (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): LayerScale()
    (drop_path2): Identity()
  )
  (20): Block(
    (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1024, out_features=3072, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1024, out_features=1024, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): LayerScale()
    (drop_path1): Identity()
    (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): LayerScale()
    (drop_path2): Identity()
  )
  (21): Block(
    (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1024, out_features=3072, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1024, out_features=1024, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): LayerScale()
    (drop_path1): Identity()
    (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): LayerScale()
    (drop_path2): Identity()
  )
  (22): Block(
    (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1024, out_features=3072, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1024, out_features=1024, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): LayerScale()
    (drop_path1): Identity()
    (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): LayerScale()
    (drop_path2): Identity()
  )
  (23): Block(
    (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1024, out_features=3072, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1024, out_features=1024, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): LayerScale()
    (drop_path1): Identity()
    (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1024, out_features=4096, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4096, out_features=1024, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): LayerScale()
    (drop_path2): Identity()
  )
)
vision_backbone.dino_featurizer.blocks.0: Block(
  (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1024, out_features=3072, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1024, out_features=1024, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): LayerScale()
  (drop_path1): Identity()
  (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1024, out_features=4096, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4096, out_features=1024, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): LayerScale()
  (drop_path2): Identity()
)
vision_backbone.dino_featurizer.blocks.0.norm1: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.0.attn: Attention(
  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1024, out_features=1024, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.0.attn.qkv: Linear(in_features=1024, out_features=3072, bias=True)
vision_backbone.dino_featurizer.blocks.0.attn.q_norm: Identity()
vision_backbone.dino_featurizer.blocks.0.attn.k_norm: Identity()
vision_backbone.dino_featurizer.blocks.0.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.0.attn.proj: Linear(in_features=1024, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.0.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.0.ls1: LayerScale()
vision_backbone.dino_featurizer.blocks.0.drop_path1: Identity()
vision_backbone.dino_featurizer.blocks.0.norm2: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.0.mlp: Mlp(
  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.0.mlp.fc1: Linear(in_features=1024, out_features=4096, bias=True)
vision_backbone.dino_featurizer.blocks.0.mlp.act: GELU(approximate='none')
vision_backbone.dino_featurizer.blocks.0.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.0.mlp.norm: Identity()
vision_backbone.dino_featurizer.blocks.0.mlp.fc2: Linear(in_features=4096, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.0.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.0.ls2: LayerScale()
vision_backbone.dino_featurizer.blocks.0.drop_path2: Identity()
vision_backbone.dino_featurizer.blocks.1: Block(
  (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1024, out_features=3072, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1024, out_features=1024, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): LayerScale()
  (drop_path1): Identity()
  (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1024, out_features=4096, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4096, out_features=1024, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): LayerScale()
  (drop_path2): Identity()
)
vision_backbone.dino_featurizer.blocks.1.norm1: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.1.attn: Attention(
  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1024, out_features=1024, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.1.attn.qkv: Linear(in_features=1024, out_features=3072, bias=True)
vision_backbone.dino_featurizer.blocks.1.attn.q_norm: Identity()
vision_backbone.dino_featurizer.blocks.1.attn.k_norm: Identity()
vision_backbone.dino_featurizer.blocks.1.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.1.attn.proj: Linear(in_features=1024, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.1.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.1.ls1: LayerScale()
vision_backbone.dino_featurizer.blocks.1.drop_path1: Identity()
vision_backbone.dino_featurizer.blocks.1.norm2: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.1.mlp: Mlp(
  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.1.mlp.fc1: Linear(in_features=1024, out_features=4096, bias=True)
vision_backbone.dino_featurizer.blocks.1.mlp.act: GELU(approximate='none')
vision_backbone.dino_featurizer.blocks.1.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.1.mlp.norm: Identity()
vision_backbone.dino_featurizer.blocks.1.mlp.fc2: Linear(in_features=4096, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.1.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.1.ls2: LayerScale()
vision_backbone.dino_featurizer.blocks.1.drop_path2: Identity()
vision_backbone.dino_featurizer.blocks.2: Block(
  (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1024, out_features=3072, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1024, out_features=1024, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): LayerScale()
  (drop_path1): Identity()
  (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1024, out_features=4096, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4096, out_features=1024, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): LayerScale()
  (drop_path2): Identity()
)
vision_backbone.dino_featurizer.blocks.2.norm1: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.2.attn: Attention(
  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1024, out_features=1024, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.2.attn.qkv: Linear(in_features=1024, out_features=3072, bias=True)
vision_backbone.dino_featurizer.blocks.2.attn.q_norm: Identity()
vision_backbone.dino_featurizer.blocks.2.attn.k_norm: Identity()
vision_backbone.dino_featurizer.blocks.2.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.2.attn.proj: Linear(in_features=1024, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.2.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.2.ls1: LayerScale()
vision_backbone.dino_featurizer.blocks.2.drop_path1: Identity()
vision_backbone.dino_featurizer.blocks.2.norm2: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.2.mlp: Mlp(
  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.2.mlp.fc1: Linear(in_features=1024, out_features=4096, bias=True)
vision_backbone.dino_featurizer.blocks.2.mlp.act: GELU(approximate='none')
vision_backbone.dino_featurizer.blocks.2.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.2.mlp.norm: Identity()
vision_backbone.dino_featurizer.blocks.2.mlp.fc2: Linear(in_features=4096, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.2.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.2.ls2: LayerScale()
vision_backbone.dino_featurizer.blocks.2.drop_path2: Identity()
vision_backbone.dino_featurizer.blocks.3: Block(
  (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1024, out_features=3072, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1024, out_features=1024, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): LayerScale()
  (drop_path1): Identity()
  (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1024, out_features=4096, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4096, out_features=1024, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): LayerScale()
  (drop_path2): Identity()
)
vision_backbone.dino_featurizer.blocks.3.norm1: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.3.attn: Attention(
  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1024, out_features=1024, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.3.attn.qkv: Linear(in_features=1024, out_features=3072, bias=True)
vision_backbone.dino_featurizer.blocks.3.attn.q_norm: Identity()
vision_backbone.dino_featurizer.blocks.3.attn.k_norm: Identity()
vision_backbone.dino_featurizer.blocks.3.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.3.attn.proj: Linear(in_features=1024, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.3.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.3.ls1: LayerScale()
vision_backbone.dino_featurizer.blocks.3.drop_path1: Identity()
vision_backbone.dino_featurizer.blocks.3.norm2: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.3.mlp: Mlp(
  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.3.mlp.fc1: Linear(in_features=1024, out_features=4096, bias=True)
vision_backbone.dino_featurizer.blocks.3.mlp.act: GELU(approximate='none')
vision_backbone.dino_featurizer.blocks.3.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.3.mlp.norm: Identity()
vision_backbone.dino_featurizer.blocks.3.mlp.fc2: Linear(in_features=4096, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.3.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.3.ls2: LayerScale()
vision_backbone.dino_featurizer.blocks.3.drop_path2: Identity()
vision_backbone.dino_featurizer.blocks.4: Block(
  (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1024, out_features=3072, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1024, out_features=1024, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): LayerScale()
  (drop_path1): Identity()
  (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1024, out_features=4096, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4096, out_features=1024, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): LayerScale()
  (drop_path2): Identity()
)
vision_backbone.dino_featurizer.blocks.4.norm1: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.4.attn: Attention(
  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1024, out_features=1024, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.4.attn.qkv: Linear(in_features=1024, out_features=3072, bias=True)
vision_backbone.dino_featurizer.blocks.4.attn.q_norm: Identity()
vision_backbone.dino_featurizer.blocks.4.attn.k_norm: Identity()
vision_backbone.dino_featurizer.blocks.4.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.4.attn.proj: Linear(in_features=1024, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.4.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.4.ls1: LayerScale()
vision_backbone.dino_featurizer.blocks.4.drop_path1: Identity()
vision_backbone.dino_featurizer.blocks.4.norm2: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.4.mlp: Mlp(
  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.4.mlp.fc1: Linear(in_features=1024, out_features=4096, bias=True)
vision_backbone.dino_featurizer.blocks.4.mlp.act: GELU(approximate='none')
vision_backbone.dino_featurizer.blocks.4.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.4.mlp.norm: Identity()
vision_backbone.dino_featurizer.blocks.4.mlp.fc2: Linear(in_features=4096, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.4.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.4.ls2: LayerScale()
vision_backbone.dino_featurizer.blocks.4.drop_path2: Identity()
vision_backbone.dino_featurizer.blocks.5: Block(
  (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1024, out_features=3072, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1024, out_features=1024, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): LayerScale()
  (drop_path1): Identity()
  (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1024, out_features=4096, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4096, out_features=1024, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): LayerScale()
  (drop_path2): Identity()
)
vision_backbone.dino_featurizer.blocks.5.norm1: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.5.attn: Attention(
  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1024, out_features=1024, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.5.attn.qkv: Linear(in_features=1024, out_features=3072, bias=True)
vision_backbone.dino_featurizer.blocks.5.attn.q_norm: Identity()
vision_backbone.dino_featurizer.blocks.5.attn.k_norm: Identity()
vision_backbone.dino_featurizer.blocks.5.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.5.attn.proj: Linear(in_features=1024, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.5.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.5.ls1: LayerScale()
vision_backbone.dino_featurizer.blocks.5.drop_path1: Identity()
vision_backbone.dino_featurizer.blocks.5.norm2: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.5.mlp: Mlp(
  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.5.mlp.fc1: Linear(in_features=1024, out_features=4096, bias=True)
vision_backbone.dino_featurizer.blocks.5.mlp.act: GELU(approximate='none')
vision_backbone.dino_featurizer.blocks.5.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.5.mlp.norm: Identity()
vision_backbone.dino_featurizer.blocks.5.mlp.fc2: Linear(in_features=4096, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.5.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.5.ls2: LayerScale()
vision_backbone.dino_featurizer.blocks.5.drop_path2: Identity()
vision_backbone.dino_featurizer.blocks.6: Block(
  (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1024, out_features=3072, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1024, out_features=1024, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): LayerScale()
  (drop_path1): Identity()
  (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1024, out_features=4096, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4096, out_features=1024, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): LayerScale()
  (drop_path2): Identity()
)
vision_backbone.dino_featurizer.blocks.6.norm1: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.6.attn: Attention(
  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1024, out_features=1024, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.6.attn.qkv: Linear(in_features=1024, out_features=3072, bias=True)
vision_backbone.dino_featurizer.blocks.6.attn.q_norm: Identity()
vision_backbone.dino_featurizer.blocks.6.attn.k_norm: Identity()
vision_backbone.dino_featurizer.blocks.6.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.6.attn.proj: Linear(in_features=1024, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.6.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.6.ls1: LayerScale()
vision_backbone.dino_featurizer.blocks.6.drop_path1: Identity()
vision_backbone.dino_featurizer.blocks.6.norm2: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.6.mlp: Mlp(
  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.6.mlp.fc1: Linear(in_features=1024, out_features=4096, bias=True)
vision_backbone.dino_featurizer.blocks.6.mlp.act: GELU(approximate='none')
vision_backbone.dino_featurizer.blocks.6.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.6.mlp.norm: Identity()
vision_backbone.dino_featurizer.blocks.6.mlp.fc2: Linear(in_features=4096, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.6.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.6.ls2: LayerScale()
vision_backbone.dino_featurizer.blocks.6.drop_path2: Identity()
vision_backbone.dino_featurizer.blocks.7: Block(
  (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1024, out_features=3072, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1024, out_features=1024, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): LayerScale()
  (drop_path1): Identity()
  (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1024, out_features=4096, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4096, out_features=1024, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): LayerScale()
  (drop_path2): Identity()
)
vision_backbone.dino_featurizer.blocks.7.norm1: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.7.attn: Attention(
  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1024, out_features=1024, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.7.attn.qkv: Linear(in_features=1024, out_features=3072, bias=True)
vision_backbone.dino_featurizer.blocks.7.attn.q_norm: Identity()
vision_backbone.dino_featurizer.blocks.7.attn.k_norm: Identity()
vision_backbone.dino_featurizer.blocks.7.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.7.attn.proj: Linear(in_features=1024, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.7.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.7.ls1: LayerScale()
vision_backbone.dino_featurizer.blocks.7.drop_path1: Identity()
vision_backbone.dino_featurizer.blocks.7.norm2: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.7.mlp: Mlp(
  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.7.mlp.fc1: Linear(in_features=1024, out_features=4096, bias=True)
vision_backbone.dino_featurizer.blocks.7.mlp.act: GELU(approximate='none')
vision_backbone.dino_featurizer.blocks.7.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.7.mlp.norm: Identity()
vision_backbone.dino_featurizer.blocks.7.mlp.fc2: Linear(in_features=4096, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.7.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.7.ls2: LayerScale()
vision_backbone.dino_featurizer.blocks.7.drop_path2: Identity()
vision_backbone.dino_featurizer.blocks.8: Block(
  (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1024, out_features=3072, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1024, out_features=1024, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): LayerScale()
  (drop_path1): Identity()
  (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1024, out_features=4096, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4096, out_features=1024, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): LayerScale()
  (drop_path2): Identity()
)
vision_backbone.dino_featurizer.blocks.8.norm1: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.8.attn: Attention(
  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1024, out_features=1024, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.8.attn.qkv: Linear(in_features=1024, out_features=3072, bias=True)
vision_backbone.dino_featurizer.blocks.8.attn.q_norm: Identity()
vision_backbone.dino_featurizer.blocks.8.attn.k_norm: Identity()
vision_backbone.dino_featurizer.blocks.8.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.8.attn.proj: Linear(in_features=1024, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.8.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.8.ls1: LayerScale()
vision_backbone.dino_featurizer.blocks.8.drop_path1: Identity()
vision_backbone.dino_featurizer.blocks.8.norm2: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.8.mlp: Mlp(
  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.8.mlp.fc1: Linear(in_features=1024, out_features=4096, bias=True)
vision_backbone.dino_featurizer.blocks.8.mlp.act: GELU(approximate='none')
vision_backbone.dino_featurizer.blocks.8.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.8.mlp.norm: Identity()
vision_backbone.dino_featurizer.blocks.8.mlp.fc2: Linear(in_features=4096, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.8.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.8.ls2: LayerScale()
vision_backbone.dino_featurizer.blocks.8.drop_path2: Identity()
vision_backbone.dino_featurizer.blocks.9: Block(
  (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1024, out_features=3072, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1024, out_features=1024, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): LayerScale()
  (drop_path1): Identity()
  (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1024, out_features=4096, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4096, out_features=1024, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): LayerScale()
  (drop_path2): Identity()
)
vision_backbone.dino_featurizer.blocks.9.norm1: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.9.attn: Attention(
  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1024, out_features=1024, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.9.attn.qkv: Linear(in_features=1024, out_features=3072, bias=True)
vision_backbone.dino_featurizer.blocks.9.attn.q_norm: Identity()
vision_backbone.dino_featurizer.blocks.9.attn.k_norm: Identity()
vision_backbone.dino_featurizer.blocks.9.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.9.attn.proj: Linear(in_features=1024, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.9.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.9.ls1: LayerScale()
vision_backbone.dino_featurizer.blocks.9.drop_path1: Identity()
vision_backbone.dino_featurizer.blocks.9.norm2: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.9.mlp: Mlp(
  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.9.mlp.fc1: Linear(in_features=1024, out_features=4096, bias=True)
vision_backbone.dino_featurizer.blocks.9.mlp.act: GELU(approximate='none')
vision_backbone.dino_featurizer.blocks.9.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.9.mlp.norm: Identity()
vision_backbone.dino_featurizer.blocks.9.mlp.fc2: Linear(in_features=4096, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.9.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.9.ls2: LayerScale()
vision_backbone.dino_featurizer.blocks.9.drop_path2: Identity()
vision_backbone.dino_featurizer.blocks.10: Block(
  (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1024, out_features=3072, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1024, out_features=1024, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): LayerScale()
  (drop_path1): Identity()
  (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1024, out_features=4096, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4096, out_features=1024, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): LayerScale()
  (drop_path2): Identity()
)
vision_backbone.dino_featurizer.blocks.10.norm1: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.10.attn: Attention(
  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1024, out_features=1024, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.10.attn.qkv: Linear(in_features=1024, out_features=3072, bias=True)
vision_backbone.dino_featurizer.blocks.10.attn.q_norm: Identity()
vision_backbone.dino_featurizer.blocks.10.attn.k_norm: Identity()
vision_backbone.dino_featurizer.blocks.10.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.10.attn.proj: Linear(in_features=1024, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.10.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.10.ls1: LayerScale()
vision_backbone.dino_featurizer.blocks.10.drop_path1: Identity()
vision_backbone.dino_featurizer.blocks.10.norm2: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.10.mlp: Mlp(
  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.10.mlp.fc1: Linear(in_features=1024, out_features=4096, bias=True)
vision_backbone.dino_featurizer.blocks.10.mlp.act: GELU(approximate='none')
vision_backbone.dino_featurizer.blocks.10.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.10.mlp.norm: Identity()
vision_backbone.dino_featurizer.blocks.10.mlp.fc2: Linear(in_features=4096, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.10.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.10.ls2: LayerScale()
vision_backbone.dino_featurizer.blocks.10.drop_path2: Identity()
vision_backbone.dino_featurizer.blocks.11: Block(
  (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1024, out_features=3072, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1024, out_features=1024, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): LayerScale()
  (drop_path1): Identity()
  (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1024, out_features=4096, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4096, out_features=1024, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): LayerScale()
  (drop_path2): Identity()
)
vision_backbone.dino_featurizer.blocks.11.norm1: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.11.attn: Attention(
  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1024, out_features=1024, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.11.attn.qkv: Linear(in_features=1024, out_features=3072, bias=True)
vision_backbone.dino_featurizer.blocks.11.attn.q_norm: Identity()
vision_backbone.dino_featurizer.blocks.11.attn.k_norm: Identity()
vision_backbone.dino_featurizer.blocks.11.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.11.attn.proj: Linear(in_features=1024, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.11.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.11.ls1: LayerScale()
vision_backbone.dino_featurizer.blocks.11.drop_path1: Identity()
vision_backbone.dino_featurizer.blocks.11.norm2: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.11.mlp: Mlp(
  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.11.mlp.fc1: Linear(in_features=1024, out_features=4096, bias=True)
vision_backbone.dino_featurizer.blocks.11.mlp.act: GELU(approximate='none')
vision_backbone.dino_featurizer.blocks.11.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.11.mlp.norm: Identity()
vision_backbone.dino_featurizer.blocks.11.mlp.fc2: Linear(in_features=4096, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.11.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.11.ls2: LayerScale()
vision_backbone.dino_featurizer.blocks.11.drop_path2: Identity()
vision_backbone.dino_featurizer.blocks.12: Block(
  (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1024, out_features=3072, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1024, out_features=1024, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): LayerScale()
  (drop_path1): Identity()
  (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1024, out_features=4096, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4096, out_features=1024, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): LayerScale()
  (drop_path2): Identity()
)
vision_backbone.dino_featurizer.blocks.12.norm1: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.12.attn: Attention(
  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1024, out_features=1024, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.12.attn.qkv: Linear(in_features=1024, out_features=3072, bias=True)
vision_backbone.dino_featurizer.blocks.12.attn.q_norm: Identity()
vision_backbone.dino_featurizer.blocks.12.attn.k_norm: Identity()
vision_backbone.dino_featurizer.blocks.12.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.12.attn.proj: Linear(in_features=1024, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.12.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.12.ls1: LayerScale()
vision_backbone.dino_featurizer.blocks.12.drop_path1: Identity()
vision_backbone.dino_featurizer.blocks.12.norm2: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.12.mlp: Mlp(
  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.12.mlp.fc1: Linear(in_features=1024, out_features=4096, bias=True)
vision_backbone.dino_featurizer.blocks.12.mlp.act: GELU(approximate='none')
vision_backbone.dino_featurizer.blocks.12.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.12.mlp.norm: Identity()
vision_backbone.dino_featurizer.blocks.12.mlp.fc2: Linear(in_features=4096, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.12.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.12.ls2: LayerScale()
vision_backbone.dino_featurizer.blocks.12.drop_path2: Identity()
vision_backbone.dino_featurizer.blocks.13: Block(
  (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1024, out_features=3072, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1024, out_features=1024, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): LayerScale()
  (drop_path1): Identity()
  (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1024, out_features=4096, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4096, out_features=1024, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): LayerScale()
  (drop_path2): Identity()
)
vision_backbone.dino_featurizer.blocks.13.norm1: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.13.attn: Attention(
  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1024, out_features=1024, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.13.attn.qkv: Linear(in_features=1024, out_features=3072, bias=True)
vision_backbone.dino_featurizer.blocks.13.attn.q_norm: Identity()
vision_backbone.dino_featurizer.blocks.13.attn.k_norm: Identity()
vision_backbone.dino_featurizer.blocks.13.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.13.attn.proj: Linear(in_features=1024, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.13.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.13.ls1: LayerScale()
vision_backbone.dino_featurizer.blocks.13.drop_path1: Identity()
vision_backbone.dino_featurizer.blocks.13.norm2: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.13.mlp: Mlp(
  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.13.mlp.fc1: Linear(in_features=1024, out_features=4096, bias=True)
vision_backbone.dino_featurizer.blocks.13.mlp.act: GELU(approximate='none')
vision_backbone.dino_featurizer.blocks.13.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.13.mlp.norm: Identity()
vision_backbone.dino_featurizer.blocks.13.mlp.fc2: Linear(in_features=4096, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.13.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.13.ls2: LayerScale()
vision_backbone.dino_featurizer.blocks.13.drop_path2: Identity()
vision_backbone.dino_featurizer.blocks.14: Block(
  (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1024, out_features=3072, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1024, out_features=1024, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): LayerScale()
  (drop_path1): Identity()
  (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1024, out_features=4096, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4096, out_features=1024, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): LayerScale()
  (drop_path2): Identity()
)
vision_backbone.dino_featurizer.blocks.14.norm1: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.14.attn: Attention(
  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1024, out_features=1024, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.14.attn.qkv: Linear(in_features=1024, out_features=3072, bias=True)
vision_backbone.dino_featurizer.blocks.14.attn.q_norm: Identity()
vision_backbone.dino_featurizer.blocks.14.attn.k_norm: Identity()
vision_backbone.dino_featurizer.blocks.14.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.14.attn.proj: Linear(in_features=1024, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.14.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.14.ls1: LayerScale()
vision_backbone.dino_featurizer.blocks.14.drop_path1: Identity()
vision_backbone.dino_featurizer.blocks.14.norm2: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.14.mlp: Mlp(
  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.14.mlp.fc1: Linear(in_features=1024, out_features=4096, bias=True)
vision_backbone.dino_featurizer.blocks.14.mlp.act: GELU(approximate='none')
vision_backbone.dino_featurizer.blocks.14.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.14.mlp.norm: Identity()
vision_backbone.dino_featurizer.blocks.14.mlp.fc2: Linear(in_features=4096, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.14.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.14.ls2: LayerScale()
vision_backbone.dino_featurizer.blocks.14.drop_path2: Identity()
vision_backbone.dino_featurizer.blocks.15: Block(
  (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1024, out_features=3072, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1024, out_features=1024, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): LayerScale()
  (drop_path1): Identity()
  (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1024, out_features=4096, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4096, out_features=1024, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): LayerScale()
  (drop_path2): Identity()
)
vision_backbone.dino_featurizer.blocks.15.norm1: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.15.attn: Attention(
  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1024, out_features=1024, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.15.attn.qkv: Linear(in_features=1024, out_features=3072, bias=True)
vision_backbone.dino_featurizer.blocks.15.attn.q_norm: Identity()
vision_backbone.dino_featurizer.blocks.15.attn.k_norm: Identity()
vision_backbone.dino_featurizer.blocks.15.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.15.attn.proj: Linear(in_features=1024, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.15.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.15.ls1: LayerScale()
vision_backbone.dino_featurizer.blocks.15.drop_path1: Identity()
vision_backbone.dino_featurizer.blocks.15.norm2: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.15.mlp: Mlp(
  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.15.mlp.fc1: Linear(in_features=1024, out_features=4096, bias=True)
vision_backbone.dino_featurizer.blocks.15.mlp.act: GELU(approximate='none')
vision_backbone.dino_featurizer.blocks.15.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.15.mlp.norm: Identity()
vision_backbone.dino_featurizer.blocks.15.mlp.fc2: Linear(in_features=4096, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.15.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.15.ls2: LayerScale()
vision_backbone.dino_featurizer.blocks.15.drop_path2: Identity()
vision_backbone.dino_featurizer.blocks.16: Block(
  (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1024, out_features=3072, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1024, out_features=1024, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): LayerScale()
  (drop_path1): Identity()
  (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1024, out_features=4096, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4096, out_features=1024, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): LayerScale()
  (drop_path2): Identity()
)
vision_backbone.dino_featurizer.blocks.16.norm1: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.16.attn: Attention(
  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1024, out_features=1024, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.16.attn.qkv: Linear(in_features=1024, out_features=3072, bias=True)
vision_backbone.dino_featurizer.blocks.16.attn.q_norm: Identity()
vision_backbone.dino_featurizer.blocks.16.attn.k_norm: Identity()
vision_backbone.dino_featurizer.blocks.16.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.16.attn.proj: Linear(in_features=1024, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.16.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.16.ls1: LayerScale()
vision_backbone.dino_featurizer.blocks.16.drop_path1: Identity()
vision_backbone.dino_featurizer.blocks.16.norm2: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.16.mlp: Mlp(
  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.16.mlp.fc1: Linear(in_features=1024, out_features=4096, bias=True)
vision_backbone.dino_featurizer.blocks.16.mlp.act: GELU(approximate='none')
vision_backbone.dino_featurizer.blocks.16.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.16.mlp.norm: Identity()
vision_backbone.dino_featurizer.blocks.16.mlp.fc2: Linear(in_features=4096, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.16.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.16.ls2: LayerScale()
vision_backbone.dino_featurizer.blocks.16.drop_path2: Identity()
vision_backbone.dino_featurizer.blocks.17: Block(
  (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1024, out_features=3072, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1024, out_features=1024, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): LayerScale()
  (drop_path1): Identity()
  (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1024, out_features=4096, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4096, out_features=1024, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): LayerScale()
  (drop_path2): Identity()
)
vision_backbone.dino_featurizer.blocks.17.norm1: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.17.attn: Attention(
  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1024, out_features=1024, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.17.attn.qkv: Linear(in_features=1024, out_features=3072, bias=True)
vision_backbone.dino_featurizer.blocks.17.attn.q_norm: Identity()
vision_backbone.dino_featurizer.blocks.17.attn.k_norm: Identity()
vision_backbone.dino_featurizer.blocks.17.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.17.attn.proj: Linear(in_features=1024, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.17.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.17.ls1: LayerScale()
vision_backbone.dino_featurizer.blocks.17.drop_path1: Identity()
vision_backbone.dino_featurizer.blocks.17.norm2: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.17.mlp: Mlp(
  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.17.mlp.fc1: Linear(in_features=1024, out_features=4096, bias=True)
vision_backbone.dino_featurizer.blocks.17.mlp.act: GELU(approximate='none')
vision_backbone.dino_featurizer.blocks.17.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.17.mlp.norm: Identity()
vision_backbone.dino_featurizer.blocks.17.mlp.fc2: Linear(in_features=4096, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.17.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.17.ls2: LayerScale()
vision_backbone.dino_featurizer.blocks.17.drop_path2: Identity()
vision_backbone.dino_featurizer.blocks.18: Block(
  (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1024, out_features=3072, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1024, out_features=1024, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): LayerScale()
  (drop_path1): Identity()
  (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1024, out_features=4096, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4096, out_features=1024, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): LayerScale()
  (drop_path2): Identity()
)
vision_backbone.dino_featurizer.blocks.18.norm1: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.18.attn: Attention(
  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1024, out_features=1024, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.18.attn.qkv: Linear(in_features=1024, out_features=3072, bias=True)
vision_backbone.dino_featurizer.blocks.18.attn.q_norm: Identity()
vision_backbone.dino_featurizer.blocks.18.attn.k_norm: Identity()
vision_backbone.dino_featurizer.blocks.18.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.18.attn.proj: Linear(in_features=1024, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.18.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.18.ls1: LayerScale()
vision_backbone.dino_featurizer.blocks.18.drop_path1: Identity()
vision_backbone.dino_featurizer.blocks.18.norm2: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.18.mlp: Mlp(
  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.18.mlp.fc1: Linear(in_features=1024, out_features=4096, bias=True)
vision_backbone.dino_featurizer.blocks.18.mlp.act: GELU(approximate='none')
vision_backbone.dino_featurizer.blocks.18.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.18.mlp.norm: Identity()
vision_backbone.dino_featurizer.blocks.18.mlp.fc2: Linear(in_features=4096, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.18.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.18.ls2: LayerScale()
vision_backbone.dino_featurizer.blocks.18.drop_path2: Identity()
vision_backbone.dino_featurizer.blocks.19: Block(
  (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1024, out_features=3072, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1024, out_features=1024, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): LayerScale()
  (drop_path1): Identity()
  (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1024, out_features=4096, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4096, out_features=1024, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): LayerScale()
  (drop_path2): Identity()
)
vision_backbone.dino_featurizer.blocks.19.norm1: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.19.attn: Attention(
  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1024, out_features=1024, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.19.attn.qkv: Linear(in_features=1024, out_features=3072, bias=True)
vision_backbone.dino_featurizer.blocks.19.attn.q_norm: Identity()
vision_backbone.dino_featurizer.blocks.19.attn.k_norm: Identity()
vision_backbone.dino_featurizer.blocks.19.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.19.attn.proj: Linear(in_features=1024, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.19.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.19.ls1: LayerScale()
vision_backbone.dino_featurizer.blocks.19.drop_path1: Identity()
vision_backbone.dino_featurizer.blocks.19.norm2: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.19.mlp: Mlp(
  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.19.mlp.fc1: Linear(in_features=1024, out_features=4096, bias=True)
vision_backbone.dino_featurizer.blocks.19.mlp.act: GELU(approximate='none')
vision_backbone.dino_featurizer.blocks.19.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.19.mlp.norm: Identity()
vision_backbone.dino_featurizer.blocks.19.mlp.fc2: Linear(in_features=4096, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.19.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.19.ls2: LayerScale()
vision_backbone.dino_featurizer.blocks.19.drop_path2: Identity()
vision_backbone.dino_featurizer.blocks.20: Block(
  (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1024, out_features=3072, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1024, out_features=1024, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): LayerScale()
  (drop_path1): Identity()
  (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1024, out_features=4096, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4096, out_features=1024, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): LayerScale()
  (drop_path2): Identity()
)
vision_backbone.dino_featurizer.blocks.20.norm1: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.20.attn: Attention(
  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1024, out_features=1024, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.20.attn.qkv: Linear(in_features=1024, out_features=3072, bias=True)
vision_backbone.dino_featurizer.blocks.20.attn.q_norm: Identity()
vision_backbone.dino_featurizer.blocks.20.attn.k_norm: Identity()
vision_backbone.dino_featurizer.blocks.20.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.20.attn.proj: Linear(in_features=1024, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.20.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.20.ls1: LayerScale()
vision_backbone.dino_featurizer.blocks.20.drop_path1: Identity()
vision_backbone.dino_featurizer.blocks.20.norm2: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.20.mlp: Mlp(
  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.20.mlp.fc1: Linear(in_features=1024, out_features=4096, bias=True)
vision_backbone.dino_featurizer.blocks.20.mlp.act: GELU(approximate='none')
vision_backbone.dino_featurizer.blocks.20.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.20.mlp.norm: Identity()
vision_backbone.dino_featurizer.blocks.20.mlp.fc2: Linear(in_features=4096, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.20.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.20.ls2: LayerScale()
vision_backbone.dino_featurizer.blocks.20.drop_path2: Identity()
vision_backbone.dino_featurizer.blocks.21: Block(
  (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1024, out_features=3072, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1024, out_features=1024, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): LayerScale()
  (drop_path1): Identity()
  (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1024, out_features=4096, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4096, out_features=1024, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): LayerScale()
  (drop_path2): Identity()
)
vision_backbone.dino_featurizer.blocks.21.norm1: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.21.attn: Attention(
  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1024, out_features=1024, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.21.attn.qkv: Linear(in_features=1024, out_features=3072, bias=True)
vision_backbone.dino_featurizer.blocks.21.attn.q_norm: Identity()
vision_backbone.dino_featurizer.blocks.21.attn.k_norm: Identity()
vision_backbone.dino_featurizer.blocks.21.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.21.attn.proj: Linear(in_features=1024, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.21.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.21.ls1: LayerScale()
vision_backbone.dino_featurizer.blocks.21.drop_path1: Identity()
vision_backbone.dino_featurizer.blocks.21.norm2: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.21.mlp: Mlp(
  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.21.mlp.fc1: Linear(in_features=1024, out_features=4096, bias=True)
vision_backbone.dino_featurizer.blocks.21.mlp.act: GELU(approximate='none')
vision_backbone.dino_featurizer.blocks.21.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.21.mlp.norm: Identity()
vision_backbone.dino_featurizer.blocks.21.mlp.fc2: Linear(in_features=4096, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.21.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.21.ls2: LayerScale()
vision_backbone.dino_featurizer.blocks.21.drop_path2: Identity()
vision_backbone.dino_featurizer.blocks.22: Block(
  (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1024, out_features=3072, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1024, out_features=1024, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): LayerScale()
  (drop_path1): Identity()
  (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1024, out_features=4096, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4096, out_features=1024, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): LayerScale()
  (drop_path2): Identity()
)
vision_backbone.dino_featurizer.blocks.22.norm1: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.22.attn: Attention(
  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1024, out_features=1024, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.22.attn.qkv: Linear(in_features=1024, out_features=3072, bias=True)
vision_backbone.dino_featurizer.blocks.22.attn.q_norm: Identity()
vision_backbone.dino_featurizer.blocks.22.attn.k_norm: Identity()
vision_backbone.dino_featurizer.blocks.22.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.22.attn.proj: Linear(in_features=1024, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.22.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.22.ls1: LayerScale()
vision_backbone.dino_featurizer.blocks.22.drop_path1: Identity()
vision_backbone.dino_featurizer.blocks.22.norm2: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.22.mlp: Mlp(
  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.22.mlp.fc1: Linear(in_features=1024, out_features=4096, bias=True)
vision_backbone.dino_featurizer.blocks.22.mlp.act: GELU(approximate='none')
vision_backbone.dino_featurizer.blocks.22.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.22.mlp.norm: Identity()
vision_backbone.dino_featurizer.blocks.22.mlp.fc2: Linear(in_features=4096, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.22.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.22.ls2: LayerScale()
vision_backbone.dino_featurizer.blocks.22.drop_path2: Identity()
vision_backbone.dino_featurizer.blocks.23: Block(
  (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1024, out_features=3072, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1024, out_features=1024, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): LayerScale()
  (drop_path1): Identity()
  (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1024, out_features=4096, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4096, out_features=1024, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): LayerScale()
  (drop_path2): Identity()
)
vision_backbone.dino_featurizer.blocks.23.norm1: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.23.attn: Attention(
  (qkv): Linear(in_features=1024, out_features=3072, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1024, out_features=1024, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.23.attn.qkv: Linear(in_features=1024, out_features=3072, bias=True)
vision_backbone.dino_featurizer.blocks.23.attn.q_norm: Identity()
vision_backbone.dino_featurizer.blocks.23.attn.k_norm: Identity()
vision_backbone.dino_featurizer.blocks.23.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.23.attn.proj: Linear(in_features=1024, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.23.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.23.ls1: LayerScale()
vision_backbone.dino_featurizer.blocks.23.drop_path1: Identity()
vision_backbone.dino_featurizer.blocks.23.norm2: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.blocks.23.mlp: Mlp(
  (fc1): Linear(in_features=1024, out_features=4096, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4096, out_features=1024, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.dino_featurizer.blocks.23.mlp.fc1: Linear(in_features=1024, out_features=4096, bias=True)
vision_backbone.dino_featurizer.blocks.23.mlp.act: GELU(approximate='none')
vision_backbone.dino_featurizer.blocks.23.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.23.mlp.norm: Identity()
vision_backbone.dino_featurizer.blocks.23.mlp.fc2: Linear(in_features=4096, out_features=1024, bias=True)
vision_backbone.dino_featurizer.blocks.23.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.blocks.23.ls2: LayerScale()
vision_backbone.dino_featurizer.blocks.23.drop_path2: Identity()
vision_backbone.dino_featurizer.norm: LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
vision_backbone.dino_featurizer.fc_norm: Identity()
vision_backbone.dino_featurizer.head_drop: Dropout(p=0.0, inplace=False)
vision_backbone.dino_featurizer.head: Identity()
vision_backbone.siglip_featurizer: VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14))
    (norm): Identity()
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (patch_drop): Identity()
  (norm_pre): Identity()
  (blocks): Sequential(
    (0): Block(
      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1152, out_features=3456, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1152, out_features=1152, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1152, out_features=4304, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4304, out_features=1152, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1152, out_features=3456, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1152, out_features=1152, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1152, out_features=4304, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4304, out_features=1152, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (2): Block(
      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1152, out_features=3456, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1152, out_features=1152, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1152, out_features=4304, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4304, out_features=1152, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (3): Block(
      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1152, out_features=3456, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1152, out_features=1152, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1152, out_features=4304, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4304, out_features=1152, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (4): Block(
      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1152, out_features=3456, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1152, out_features=1152, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1152, out_features=4304, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4304, out_features=1152, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (5): Block(
      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1152, out_features=3456, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1152, out_features=1152, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1152, out_features=4304, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4304, out_features=1152, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (6): Block(
      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1152, out_features=3456, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1152, out_features=1152, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1152, out_features=4304, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4304, out_features=1152, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (7): Block(
      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1152, out_features=3456, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1152, out_features=1152, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1152, out_features=4304, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4304, out_features=1152, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (8): Block(
      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1152, out_features=3456, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1152, out_features=1152, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1152, out_features=4304, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4304, out_features=1152, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (9): Block(
      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1152, out_features=3456, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1152, out_features=1152, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1152, out_features=4304, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4304, out_features=1152, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (10): Block(
      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1152, out_features=3456, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1152, out_features=1152, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1152, out_features=4304, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4304, out_features=1152, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (11): Block(
      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1152, out_features=3456, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1152, out_features=1152, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1152, out_features=4304, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4304, out_features=1152, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (12): Block(
      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1152, out_features=3456, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1152, out_features=1152, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1152, out_features=4304, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4304, out_features=1152, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (13): Block(
      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1152, out_features=3456, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1152, out_features=1152, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1152, out_features=4304, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4304, out_features=1152, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (14): Block(
      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1152, out_features=3456, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1152, out_features=1152, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1152, out_features=4304, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4304, out_features=1152, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (15): Block(
      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1152, out_features=3456, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1152, out_features=1152, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1152, out_features=4304, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4304, out_features=1152, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (16): Block(
      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1152, out_features=3456, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1152, out_features=1152, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1152, out_features=4304, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4304, out_features=1152, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (17): Block(
      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1152, out_features=3456, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1152, out_features=1152, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1152, out_features=4304, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4304, out_features=1152, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (18): Block(
      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1152, out_features=3456, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1152, out_features=1152, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1152, out_features=4304, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4304, out_features=1152, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (19): Block(
      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1152, out_features=3456, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1152, out_features=1152, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1152, out_features=4304, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4304, out_features=1152, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (20): Block(
      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1152, out_features=3456, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1152, out_features=1152, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1152, out_features=4304, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4304, out_features=1152, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (21): Block(
      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1152, out_features=3456, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1152, out_features=1152, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1152, out_features=4304, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4304, out_features=1152, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (22): Block(
      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1152, out_features=3456, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1152, out_features=1152, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1152, out_features=4304, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4304, out_features=1152, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (23): Block(
      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1152, out_features=3456, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1152, out_features=1152, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1152, out_features=4304, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4304, out_features=1152, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (24): Block(
      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1152, out_features=3456, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1152, out_features=1152, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1152, out_features=4304, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4304, out_features=1152, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (25): Block(
      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1152, out_features=3456, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1152, out_features=1152, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1152, out_features=4304, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4304, out_features=1152, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (26): Block(
      (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1152, out_features=3456, bias=True)
        (q_norm): Identity()
        (k_norm): Identity()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1152, out_features=1152, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1152, out_features=4304, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (norm): Identity()
        (fc2): Linear(in_features=4304, out_features=1152, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
  )
  (norm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (attn_pool): AttentionPoolLatent(
    (q): Linear(in_features=1152, out_features=1152, bias=True)
    (kv): Linear(in_features=1152, out_features=2304, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (proj): Linear(in_features=1152, out_features=1152, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
    (norm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1152, out_features=4304, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4304, out_features=1152, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
  )
  (fc_norm): Identity()
  (head_drop): Dropout(p=0.0, inplace=False)
  (head): Identity()
)
vision_backbone.siglip_featurizer.patch_embed: PatchEmbed(
  (proj): Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14))
  (norm): Identity()
)
vision_backbone.siglip_featurizer.patch_embed.proj: Conv2d(3, 1152, kernel_size=(14, 14), stride=(14, 14))
vision_backbone.siglip_featurizer.patch_embed.norm: Identity()
vision_backbone.siglip_featurizer.pos_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.patch_drop: Identity()
vision_backbone.siglip_featurizer.norm_pre: Identity()
vision_backbone.siglip_featurizer.blocks: Sequential(
  (0): Block(
    (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1152, out_features=3456, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1152, out_features=1152, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): Identity()
    (drop_path1): Identity()
    (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1152, out_features=4304, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4304, out_features=1152, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): Identity()
    (drop_path2): Identity()
  )
  (1): Block(
    (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1152, out_features=3456, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1152, out_features=1152, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): Identity()
    (drop_path1): Identity()
    (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1152, out_features=4304, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4304, out_features=1152, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): Identity()
    (drop_path2): Identity()
  )
  (2): Block(
    (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1152, out_features=3456, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1152, out_features=1152, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): Identity()
    (drop_path1): Identity()
    (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1152, out_features=4304, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4304, out_features=1152, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): Identity()
    (drop_path2): Identity()
  )
  (3): Block(
    (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1152, out_features=3456, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1152, out_features=1152, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): Identity()
    (drop_path1): Identity()
    (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1152, out_features=4304, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4304, out_features=1152, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): Identity()
    (drop_path2): Identity()
  )
  (4): Block(
    (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1152, out_features=3456, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1152, out_features=1152, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): Identity()
    (drop_path1): Identity()
    (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1152, out_features=4304, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4304, out_features=1152, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): Identity()
    (drop_path2): Identity()
  )
  (5): Block(
    (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1152, out_features=3456, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1152, out_features=1152, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): Identity()
    (drop_path1): Identity()
    (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1152, out_features=4304, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4304, out_features=1152, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): Identity()
    (drop_path2): Identity()
  )
  (6): Block(
    (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1152, out_features=3456, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1152, out_features=1152, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): Identity()
    (drop_path1): Identity()
    (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1152, out_features=4304, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4304, out_features=1152, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): Identity()
    (drop_path2): Identity()
  )
  (7): Block(
    (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1152, out_features=3456, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1152, out_features=1152, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): Identity()
    (drop_path1): Identity()
    (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1152, out_features=4304, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4304, out_features=1152, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): Identity()
    (drop_path2): Identity()
  )
  (8): Block(
    (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1152, out_features=3456, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1152, out_features=1152, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): Identity()
    (drop_path1): Identity()
    (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1152, out_features=4304, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4304, out_features=1152, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): Identity()
    (drop_path2): Identity()
  )
  (9): Block(
    (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1152, out_features=3456, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1152, out_features=1152, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): Identity()
    (drop_path1): Identity()
    (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1152, out_features=4304, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4304, out_features=1152, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): Identity()
    (drop_path2): Identity()
  )
  (10): Block(
    (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1152, out_features=3456, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1152, out_features=1152, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): Identity()
    (drop_path1): Identity()
    (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1152, out_features=4304, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4304, out_features=1152, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): Identity()
    (drop_path2): Identity()
  )
  (11): Block(
    (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1152, out_features=3456, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1152, out_features=1152, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): Identity()
    (drop_path1): Identity()
    (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1152, out_features=4304, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4304, out_features=1152, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): Identity()
    (drop_path2): Identity()
  )
  (12): Block(
    (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1152, out_features=3456, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1152, out_features=1152, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): Identity()
    (drop_path1): Identity()
    (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1152, out_features=4304, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4304, out_features=1152, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): Identity()
    (drop_path2): Identity()
  )
  (13): Block(
    (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1152, out_features=3456, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1152, out_features=1152, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): Identity()
    (drop_path1): Identity()
    (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1152, out_features=4304, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4304, out_features=1152, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): Identity()
    (drop_path2): Identity()
  )
  (14): Block(
    (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1152, out_features=3456, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1152, out_features=1152, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): Identity()
    (drop_path1): Identity()
    (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1152, out_features=4304, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4304, out_features=1152, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): Identity()
    (drop_path2): Identity()
  )
  (15): Block(
    (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1152, out_features=3456, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1152, out_features=1152, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): Identity()
    (drop_path1): Identity()
    (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1152, out_features=4304, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4304, out_features=1152, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): Identity()
    (drop_path2): Identity()
  )
  (16): Block(
    (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1152, out_features=3456, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1152, out_features=1152, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): Identity()
    (drop_path1): Identity()
    (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1152, out_features=4304, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4304, out_features=1152, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): Identity()
    (drop_path2): Identity()
  )
  (17): Block(
    (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1152, out_features=3456, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1152, out_features=1152, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): Identity()
    (drop_path1): Identity()
    (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1152, out_features=4304, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4304, out_features=1152, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): Identity()
    (drop_path2): Identity()
  )
  (18): Block(
    (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1152, out_features=3456, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1152, out_features=1152, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): Identity()
    (drop_path1): Identity()
    (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1152, out_features=4304, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4304, out_features=1152, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): Identity()
    (drop_path2): Identity()
  )
  (19): Block(
    (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1152, out_features=3456, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1152, out_features=1152, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): Identity()
    (drop_path1): Identity()
    (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1152, out_features=4304, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4304, out_features=1152, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): Identity()
    (drop_path2): Identity()
  )
  (20): Block(
    (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1152, out_features=3456, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1152, out_features=1152, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): Identity()
    (drop_path1): Identity()
    (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1152, out_features=4304, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4304, out_features=1152, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): Identity()
    (drop_path2): Identity()
  )
  (21): Block(
    (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1152, out_features=3456, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1152, out_features=1152, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): Identity()
    (drop_path1): Identity()
    (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1152, out_features=4304, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4304, out_features=1152, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): Identity()
    (drop_path2): Identity()
  )
  (22): Block(
    (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1152, out_features=3456, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1152, out_features=1152, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): Identity()
    (drop_path1): Identity()
    (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1152, out_features=4304, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4304, out_features=1152, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): Identity()
    (drop_path2): Identity()
  )
  (23): Block(
    (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1152, out_features=3456, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1152, out_features=1152, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): Identity()
    (drop_path1): Identity()
    (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1152, out_features=4304, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4304, out_features=1152, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): Identity()
    (drop_path2): Identity()
  )
  (24): Block(
    (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1152, out_features=3456, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1152, out_features=1152, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): Identity()
    (drop_path1): Identity()
    (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1152, out_features=4304, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4304, out_features=1152, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): Identity()
    (drop_path2): Identity()
  )
  (25): Block(
    (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1152, out_features=3456, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1152, out_features=1152, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): Identity()
    (drop_path1): Identity()
    (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1152, out_features=4304, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4304, out_features=1152, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): Identity()
    (drop_path2): Identity()
  )
  (26): Block(
    (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (attn): Attention(
      (qkv): Linear(in_features=1152, out_features=3456, bias=True)
      (q_norm): Identity()
      (k_norm): Identity()
      (attn_drop): Dropout(p=0.0, inplace=False)
      (proj): Linear(in_features=1152, out_features=1152, bias=True)
      (proj_drop): Dropout(p=0.0, inplace=False)
    )
    (ls1): Identity()
    (drop_path1): Identity()
    (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
    (mlp): Mlp(
      (fc1): Linear(in_features=1152, out_features=4304, bias=True)
      (act): GELU(approximate='none')
      (drop1): Dropout(p=0.0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=4304, out_features=1152, bias=True)
      (drop2): Dropout(p=0.0, inplace=False)
    )
    (ls2): Identity()
    (drop_path2): Identity()
  )
)
vision_backbone.siglip_featurizer.blocks.0: Block(
  (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1152, out_features=3456, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1152, out_features=1152, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): Identity()
  (drop_path1): Identity()
  (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1152, out_features=4304, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4304, out_features=1152, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): Identity()
  (drop_path2): Identity()
)
vision_backbone.siglip_featurizer.blocks.0.norm1: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.0.attn: Attention(
  (qkv): Linear(in_features=1152, out_features=3456, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1152, out_features=1152, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.0.attn.qkv: Linear(in_features=1152, out_features=3456, bias=True)
vision_backbone.siglip_featurizer.blocks.0.attn.q_norm: Identity()
vision_backbone.siglip_featurizer.blocks.0.attn.k_norm: Identity()
vision_backbone.siglip_featurizer.blocks.0.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.0.attn.proj: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.0.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.0.ls1: Identity()
vision_backbone.siglip_featurizer.blocks.0.drop_path1: Identity()
vision_backbone.siglip_featurizer.blocks.0.norm2: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.0.mlp: Mlp(
  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.0.mlp.fc1: Linear(in_features=1152, out_features=4304, bias=True)
vision_backbone.siglip_featurizer.blocks.0.mlp.act: GELU(approximate='none')
vision_backbone.siglip_featurizer.blocks.0.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.0.mlp.norm: Identity()
vision_backbone.siglip_featurizer.blocks.0.mlp.fc2: Linear(in_features=4304, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.0.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.0.ls2: Identity()
vision_backbone.siglip_featurizer.blocks.0.drop_path2: Identity()
vision_backbone.siglip_featurizer.blocks.1: Block(
  (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1152, out_features=3456, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1152, out_features=1152, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): Identity()
  (drop_path1): Identity()
  (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1152, out_features=4304, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4304, out_features=1152, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): Identity()
  (drop_path2): Identity()
)
vision_backbone.siglip_featurizer.blocks.1.norm1: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.1.attn: Attention(
  (qkv): Linear(in_features=1152, out_features=3456, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1152, out_features=1152, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.1.attn.qkv: Linear(in_features=1152, out_features=3456, bias=True)
vision_backbone.siglip_featurizer.blocks.1.attn.q_norm: Identity()
vision_backbone.siglip_featurizer.blocks.1.attn.k_norm: Identity()
vision_backbone.siglip_featurizer.blocks.1.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.1.attn.proj: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.1.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.1.ls1: Identity()
vision_backbone.siglip_featurizer.blocks.1.drop_path1: Identity()
vision_backbone.siglip_featurizer.blocks.1.norm2: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.1.mlp: Mlp(
  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.1.mlp.fc1: Linear(in_features=1152, out_features=4304, bias=True)
vision_backbone.siglip_featurizer.blocks.1.mlp.act: GELU(approximate='none')
vision_backbone.siglip_featurizer.blocks.1.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.1.mlp.norm: Identity()
vision_backbone.siglip_featurizer.blocks.1.mlp.fc2: Linear(in_features=4304, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.1.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.1.ls2: Identity()
vision_backbone.siglip_featurizer.blocks.1.drop_path2: Identity()
vision_backbone.siglip_featurizer.blocks.2: Block(
  (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1152, out_features=3456, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1152, out_features=1152, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): Identity()
  (drop_path1): Identity()
  (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1152, out_features=4304, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4304, out_features=1152, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): Identity()
  (drop_path2): Identity()
)
vision_backbone.siglip_featurizer.blocks.2.norm1: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.2.attn: Attention(
  (qkv): Linear(in_features=1152, out_features=3456, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1152, out_features=1152, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.2.attn.qkv: Linear(in_features=1152, out_features=3456, bias=True)
vision_backbone.siglip_featurizer.blocks.2.attn.q_norm: Identity()
vision_backbone.siglip_featurizer.blocks.2.attn.k_norm: Identity()
vision_backbone.siglip_featurizer.blocks.2.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.2.attn.proj: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.2.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.2.ls1: Identity()
vision_backbone.siglip_featurizer.blocks.2.drop_path1: Identity()
vision_backbone.siglip_featurizer.blocks.2.norm2: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.2.mlp: Mlp(
  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.2.mlp.fc1: Linear(in_features=1152, out_features=4304, bias=True)
vision_backbone.siglip_featurizer.blocks.2.mlp.act: GELU(approximate='none')
vision_backbone.siglip_featurizer.blocks.2.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.2.mlp.norm: Identity()
vision_backbone.siglip_featurizer.blocks.2.mlp.fc2: Linear(in_features=4304, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.2.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.2.ls2: Identity()
vision_backbone.siglip_featurizer.blocks.2.drop_path2: Identity()
vision_backbone.siglip_featurizer.blocks.3: Block(
  (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1152, out_features=3456, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1152, out_features=1152, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): Identity()
  (drop_path1): Identity()
  (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1152, out_features=4304, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4304, out_features=1152, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): Identity()
  (drop_path2): Identity()
)
vision_backbone.siglip_featurizer.blocks.3.norm1: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.3.attn: Attention(
  (qkv): Linear(in_features=1152, out_features=3456, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1152, out_features=1152, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.3.attn.qkv: Linear(in_features=1152, out_features=3456, bias=True)
vision_backbone.siglip_featurizer.blocks.3.attn.q_norm: Identity()
vision_backbone.siglip_featurizer.blocks.3.attn.k_norm: Identity()
vision_backbone.siglip_featurizer.blocks.3.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.3.attn.proj: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.3.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.3.ls1: Identity()
vision_backbone.siglip_featurizer.blocks.3.drop_path1: Identity()
vision_backbone.siglip_featurizer.blocks.3.norm2: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.3.mlp: Mlp(
  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.3.mlp.fc1: Linear(in_features=1152, out_features=4304, bias=True)
vision_backbone.siglip_featurizer.blocks.3.mlp.act: GELU(approximate='none')
vision_backbone.siglip_featurizer.blocks.3.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.3.mlp.norm: Identity()
vision_backbone.siglip_featurizer.blocks.3.mlp.fc2: Linear(in_features=4304, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.3.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.3.ls2: Identity()
vision_backbone.siglip_featurizer.blocks.3.drop_path2: Identity()
vision_backbone.siglip_featurizer.blocks.4: Block(
  (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1152, out_features=3456, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1152, out_features=1152, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): Identity()
  (drop_path1): Identity()
  (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1152, out_features=4304, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4304, out_features=1152, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): Identity()
  (drop_path2): Identity()
)
vision_backbone.siglip_featurizer.blocks.4.norm1: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.4.attn: Attention(
  (qkv): Linear(in_features=1152, out_features=3456, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1152, out_features=1152, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.4.attn.qkv: Linear(in_features=1152, out_features=3456, bias=True)
vision_backbone.siglip_featurizer.blocks.4.attn.q_norm: Identity()
vision_backbone.siglip_featurizer.blocks.4.attn.k_norm: Identity()
vision_backbone.siglip_featurizer.blocks.4.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.4.attn.proj: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.4.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.4.ls1: Identity()
vision_backbone.siglip_featurizer.blocks.4.drop_path1: Identity()
vision_backbone.siglip_featurizer.blocks.4.norm2: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.4.mlp: Mlp(
  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.4.mlp.fc1: Linear(in_features=1152, out_features=4304, bias=True)
vision_backbone.siglip_featurizer.blocks.4.mlp.act: GELU(approximate='none')
vision_backbone.siglip_featurizer.blocks.4.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.4.mlp.norm: Identity()
vision_backbone.siglip_featurizer.blocks.4.mlp.fc2: Linear(in_features=4304, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.4.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.4.ls2: Identity()
vision_backbone.siglip_featurizer.blocks.4.drop_path2: Identity()
vision_backbone.siglip_featurizer.blocks.5: Block(
  (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1152, out_features=3456, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1152, out_features=1152, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): Identity()
  (drop_path1): Identity()
  (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1152, out_features=4304, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4304, out_features=1152, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): Identity()
  (drop_path2): Identity()
)
vision_backbone.siglip_featurizer.blocks.5.norm1: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.5.attn: Attention(
  (qkv): Linear(in_features=1152, out_features=3456, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1152, out_features=1152, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.5.attn.qkv: Linear(in_features=1152, out_features=3456, bias=True)
vision_backbone.siglip_featurizer.blocks.5.attn.q_norm: Identity()
vision_backbone.siglip_featurizer.blocks.5.attn.k_norm: Identity()
vision_backbone.siglip_featurizer.blocks.5.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.5.attn.proj: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.5.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.5.ls1: Identity()
vision_backbone.siglip_featurizer.blocks.5.drop_path1: Identity()
vision_backbone.siglip_featurizer.blocks.5.norm2: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.5.mlp: Mlp(
  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.5.mlp.fc1: Linear(in_features=1152, out_features=4304, bias=True)
vision_backbone.siglip_featurizer.blocks.5.mlp.act: GELU(approximate='none')
vision_backbone.siglip_featurizer.blocks.5.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.5.mlp.norm: Identity()
vision_backbone.siglip_featurizer.blocks.5.mlp.fc2: Linear(in_features=4304, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.5.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.5.ls2: Identity()
vision_backbone.siglip_featurizer.blocks.5.drop_path2: Identity()
vision_backbone.siglip_featurizer.blocks.6: Block(
  (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1152, out_features=3456, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1152, out_features=1152, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): Identity()
  (drop_path1): Identity()
  (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1152, out_features=4304, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4304, out_features=1152, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): Identity()
  (drop_path2): Identity()
)
vision_backbone.siglip_featurizer.blocks.6.norm1: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.6.attn: Attention(
  (qkv): Linear(in_features=1152, out_features=3456, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1152, out_features=1152, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.6.attn.qkv: Linear(in_features=1152, out_features=3456, bias=True)
vision_backbone.siglip_featurizer.blocks.6.attn.q_norm: Identity()
vision_backbone.siglip_featurizer.blocks.6.attn.k_norm: Identity()
vision_backbone.siglip_featurizer.blocks.6.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.6.attn.proj: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.6.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.6.ls1: Identity()
vision_backbone.siglip_featurizer.blocks.6.drop_path1: Identity()
vision_backbone.siglip_featurizer.blocks.6.norm2: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.6.mlp: Mlp(
  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.6.mlp.fc1: Linear(in_features=1152, out_features=4304, bias=True)
vision_backbone.siglip_featurizer.blocks.6.mlp.act: GELU(approximate='none')
vision_backbone.siglip_featurizer.blocks.6.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.6.mlp.norm: Identity()
vision_backbone.siglip_featurizer.blocks.6.mlp.fc2: Linear(in_features=4304, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.6.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.6.ls2: Identity()
vision_backbone.siglip_featurizer.blocks.6.drop_path2: Identity()
vision_backbone.siglip_featurizer.blocks.7: Block(
  (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1152, out_features=3456, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1152, out_features=1152, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): Identity()
  (drop_path1): Identity()
  (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1152, out_features=4304, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4304, out_features=1152, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): Identity()
  (drop_path2): Identity()
)
vision_backbone.siglip_featurizer.blocks.7.norm1: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.7.attn: Attention(
  (qkv): Linear(in_features=1152, out_features=3456, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1152, out_features=1152, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.7.attn.qkv: Linear(in_features=1152, out_features=3456, bias=True)
vision_backbone.siglip_featurizer.blocks.7.attn.q_norm: Identity()
vision_backbone.siglip_featurizer.blocks.7.attn.k_norm: Identity()
vision_backbone.siglip_featurizer.blocks.7.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.7.attn.proj: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.7.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.7.ls1: Identity()
vision_backbone.siglip_featurizer.blocks.7.drop_path1: Identity()
vision_backbone.siglip_featurizer.blocks.7.norm2: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.7.mlp: Mlp(
  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.7.mlp.fc1: Linear(in_features=1152, out_features=4304, bias=True)
vision_backbone.siglip_featurizer.blocks.7.mlp.act: GELU(approximate='none')
vision_backbone.siglip_featurizer.blocks.7.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.7.mlp.norm: Identity()
vision_backbone.siglip_featurizer.blocks.7.mlp.fc2: Linear(in_features=4304, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.7.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.7.ls2: Identity()
vision_backbone.siglip_featurizer.blocks.7.drop_path2: Identity()
vision_backbone.siglip_featurizer.blocks.8: Block(
  (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1152, out_features=3456, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1152, out_features=1152, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): Identity()
  (drop_path1): Identity()
  (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1152, out_features=4304, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4304, out_features=1152, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): Identity()
  (drop_path2): Identity()
)
vision_backbone.siglip_featurizer.blocks.8.norm1: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.8.attn: Attention(
  (qkv): Linear(in_features=1152, out_features=3456, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1152, out_features=1152, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.8.attn.qkv: Linear(in_features=1152, out_features=3456, bias=True)
vision_backbone.siglip_featurizer.blocks.8.attn.q_norm: Identity()
vision_backbone.siglip_featurizer.blocks.8.attn.k_norm: Identity()
vision_backbone.siglip_featurizer.blocks.8.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.8.attn.proj: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.8.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.8.ls1: Identity()
vision_backbone.siglip_featurizer.blocks.8.drop_path1: Identity()
vision_backbone.siglip_featurizer.blocks.8.norm2: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.8.mlp: Mlp(
  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.8.mlp.fc1: Linear(in_features=1152, out_features=4304, bias=True)
vision_backbone.siglip_featurizer.blocks.8.mlp.act: GELU(approximate='none')
vision_backbone.siglip_featurizer.blocks.8.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.8.mlp.norm: Identity()
vision_backbone.siglip_featurizer.blocks.8.mlp.fc2: Linear(in_features=4304, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.8.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.8.ls2: Identity()
vision_backbone.siglip_featurizer.blocks.8.drop_path2: Identity()
vision_backbone.siglip_featurizer.blocks.9: Block(
  (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1152, out_features=3456, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1152, out_features=1152, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): Identity()
  (drop_path1): Identity()
  (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1152, out_features=4304, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4304, out_features=1152, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): Identity()
  (drop_path2): Identity()
)
vision_backbone.siglip_featurizer.blocks.9.norm1: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.9.attn: Attention(
  (qkv): Linear(in_features=1152, out_features=3456, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1152, out_features=1152, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.9.attn.qkv: Linear(in_features=1152, out_features=3456, bias=True)
vision_backbone.siglip_featurizer.blocks.9.attn.q_norm: Identity()
vision_backbone.siglip_featurizer.blocks.9.attn.k_norm: Identity()
vision_backbone.siglip_featurizer.blocks.9.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.9.attn.proj: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.9.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.9.ls1: Identity()
vision_backbone.siglip_featurizer.blocks.9.drop_path1: Identity()
vision_backbone.siglip_featurizer.blocks.9.norm2: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.9.mlp: Mlp(
  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.9.mlp.fc1: Linear(in_features=1152, out_features=4304, bias=True)
vision_backbone.siglip_featurizer.blocks.9.mlp.act: GELU(approximate='none')
vision_backbone.siglip_featurizer.blocks.9.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.9.mlp.norm: Identity()
vision_backbone.siglip_featurizer.blocks.9.mlp.fc2: Linear(in_features=4304, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.9.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.9.ls2: Identity()
vision_backbone.siglip_featurizer.blocks.9.drop_path2: Identity()
vision_backbone.siglip_featurizer.blocks.10: Block(
  (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1152, out_features=3456, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1152, out_features=1152, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): Identity()
  (drop_path1): Identity()
  (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1152, out_features=4304, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4304, out_features=1152, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): Identity()
  (drop_path2): Identity()
)
vision_backbone.siglip_featurizer.blocks.10.norm1: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.10.attn: Attention(
  (qkv): Linear(in_features=1152, out_features=3456, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1152, out_features=1152, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.10.attn.qkv: Linear(in_features=1152, out_features=3456, bias=True)
vision_backbone.siglip_featurizer.blocks.10.attn.q_norm: Identity()
vision_backbone.siglip_featurizer.blocks.10.attn.k_norm: Identity()
vision_backbone.siglip_featurizer.blocks.10.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.10.attn.proj: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.10.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.10.ls1: Identity()
vision_backbone.siglip_featurizer.blocks.10.drop_path1: Identity()
vision_backbone.siglip_featurizer.blocks.10.norm2: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.10.mlp: Mlp(
  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.10.mlp.fc1: Linear(in_features=1152, out_features=4304, bias=True)
vision_backbone.siglip_featurizer.blocks.10.mlp.act: GELU(approximate='none')
vision_backbone.siglip_featurizer.blocks.10.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.10.mlp.norm: Identity()
vision_backbone.siglip_featurizer.blocks.10.mlp.fc2: Linear(in_features=4304, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.10.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.10.ls2: Identity()
vision_backbone.siglip_featurizer.blocks.10.drop_path2: Identity()
vision_backbone.siglip_featurizer.blocks.11: Block(
  (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1152, out_features=3456, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1152, out_features=1152, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): Identity()
  (drop_path1): Identity()
  (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1152, out_features=4304, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4304, out_features=1152, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): Identity()
  (drop_path2): Identity()
)
vision_backbone.siglip_featurizer.blocks.11.norm1: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.11.attn: Attention(
  (qkv): Linear(in_features=1152, out_features=3456, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1152, out_features=1152, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.11.attn.qkv: Linear(in_features=1152, out_features=3456, bias=True)
vision_backbone.siglip_featurizer.blocks.11.attn.q_norm: Identity()
vision_backbone.siglip_featurizer.blocks.11.attn.k_norm: Identity()
vision_backbone.siglip_featurizer.blocks.11.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.11.attn.proj: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.11.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.11.ls1: Identity()
vision_backbone.siglip_featurizer.blocks.11.drop_path1: Identity()
vision_backbone.siglip_featurizer.blocks.11.norm2: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.11.mlp: Mlp(
  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.11.mlp.fc1: Linear(in_features=1152, out_features=4304, bias=True)
vision_backbone.siglip_featurizer.blocks.11.mlp.act: GELU(approximate='none')
vision_backbone.siglip_featurizer.blocks.11.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.11.mlp.norm: Identity()
vision_backbone.siglip_featurizer.blocks.11.mlp.fc2: Linear(in_features=4304, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.11.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.11.ls2: Identity()
vision_backbone.siglip_featurizer.blocks.11.drop_path2: Identity()
vision_backbone.siglip_featurizer.blocks.12: Block(
  (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1152, out_features=3456, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1152, out_features=1152, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): Identity()
  (drop_path1): Identity()
  (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1152, out_features=4304, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4304, out_features=1152, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): Identity()
  (drop_path2): Identity()
)
vision_backbone.siglip_featurizer.blocks.12.norm1: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.12.attn: Attention(
  (qkv): Linear(in_features=1152, out_features=3456, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1152, out_features=1152, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.12.attn.qkv: Linear(in_features=1152, out_features=3456, bias=True)
vision_backbone.siglip_featurizer.blocks.12.attn.q_norm: Identity()
vision_backbone.siglip_featurizer.blocks.12.attn.k_norm: Identity()
vision_backbone.siglip_featurizer.blocks.12.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.12.attn.proj: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.12.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.12.ls1: Identity()
vision_backbone.siglip_featurizer.blocks.12.drop_path1: Identity()
vision_backbone.siglip_featurizer.blocks.12.norm2: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.12.mlp: Mlp(
  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.12.mlp.fc1: Linear(in_features=1152, out_features=4304, bias=True)
vision_backbone.siglip_featurizer.blocks.12.mlp.act: GELU(approximate='none')
vision_backbone.siglip_featurizer.blocks.12.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.12.mlp.norm: Identity()
vision_backbone.siglip_featurizer.blocks.12.mlp.fc2: Linear(in_features=4304, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.12.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.12.ls2: Identity()
vision_backbone.siglip_featurizer.blocks.12.drop_path2: Identity()
vision_backbone.siglip_featurizer.blocks.13: Block(
  (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1152, out_features=3456, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1152, out_features=1152, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): Identity()
  (drop_path1): Identity()
  (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1152, out_features=4304, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4304, out_features=1152, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): Identity()
  (drop_path2): Identity()
)
vision_backbone.siglip_featurizer.blocks.13.norm1: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.13.attn: Attention(
  (qkv): Linear(in_features=1152, out_features=3456, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1152, out_features=1152, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.13.attn.qkv: Linear(in_features=1152, out_features=3456, bias=True)
vision_backbone.siglip_featurizer.blocks.13.attn.q_norm: Identity()
vision_backbone.siglip_featurizer.blocks.13.attn.k_norm: Identity()
vision_backbone.siglip_featurizer.blocks.13.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.13.attn.proj: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.13.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.13.ls1: Identity()
vision_backbone.siglip_featurizer.blocks.13.drop_path1: Identity()
vision_backbone.siglip_featurizer.blocks.13.norm2: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.13.mlp: Mlp(
  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.13.mlp.fc1: Linear(in_features=1152, out_features=4304, bias=True)
vision_backbone.siglip_featurizer.blocks.13.mlp.act: GELU(approximate='none')
vision_backbone.siglip_featurizer.blocks.13.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.13.mlp.norm: Identity()
vision_backbone.siglip_featurizer.blocks.13.mlp.fc2: Linear(in_features=4304, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.13.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.13.ls2: Identity()
vision_backbone.siglip_featurizer.blocks.13.drop_path2: Identity()
vision_backbone.siglip_featurizer.blocks.14: Block(
  (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1152, out_features=3456, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1152, out_features=1152, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): Identity()
  (drop_path1): Identity()
  (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1152, out_features=4304, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4304, out_features=1152, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): Identity()
  (drop_path2): Identity()
)
vision_backbone.siglip_featurizer.blocks.14.norm1: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.14.attn: Attention(
  (qkv): Linear(in_features=1152, out_features=3456, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1152, out_features=1152, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.14.attn.qkv: Linear(in_features=1152, out_features=3456, bias=True)
vision_backbone.siglip_featurizer.blocks.14.attn.q_norm: Identity()
vision_backbone.siglip_featurizer.blocks.14.attn.k_norm: Identity()
vision_backbone.siglip_featurizer.blocks.14.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.14.attn.proj: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.14.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.14.ls1: Identity()
vision_backbone.siglip_featurizer.blocks.14.drop_path1: Identity()
vision_backbone.siglip_featurizer.blocks.14.norm2: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.14.mlp: Mlp(
  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.14.mlp.fc1: Linear(in_features=1152, out_features=4304, bias=True)
vision_backbone.siglip_featurizer.blocks.14.mlp.act: GELU(approximate='none')
vision_backbone.siglip_featurizer.blocks.14.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.14.mlp.norm: Identity()
vision_backbone.siglip_featurizer.blocks.14.mlp.fc2: Linear(in_features=4304, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.14.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.14.ls2: Identity()
vision_backbone.siglip_featurizer.blocks.14.drop_path2: Identity()
vision_backbone.siglip_featurizer.blocks.15: Block(
  (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1152, out_features=3456, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1152, out_features=1152, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): Identity()
  (drop_path1): Identity()
  (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1152, out_features=4304, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4304, out_features=1152, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): Identity()
  (drop_path2): Identity()
)
vision_backbone.siglip_featurizer.blocks.15.norm1: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.15.attn: Attention(
  (qkv): Linear(in_features=1152, out_features=3456, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1152, out_features=1152, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.15.attn.qkv: Linear(in_features=1152, out_features=3456, bias=True)
vision_backbone.siglip_featurizer.blocks.15.attn.q_norm: Identity()
vision_backbone.siglip_featurizer.blocks.15.attn.k_norm: Identity()
vision_backbone.siglip_featurizer.blocks.15.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.15.attn.proj: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.15.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.15.ls1: Identity()
vision_backbone.siglip_featurizer.blocks.15.drop_path1: Identity()
vision_backbone.siglip_featurizer.blocks.15.norm2: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.15.mlp: Mlp(
  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.15.mlp.fc1: Linear(in_features=1152, out_features=4304, bias=True)
vision_backbone.siglip_featurizer.blocks.15.mlp.act: GELU(approximate='none')
vision_backbone.siglip_featurizer.blocks.15.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.15.mlp.norm: Identity()
vision_backbone.siglip_featurizer.blocks.15.mlp.fc2: Linear(in_features=4304, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.15.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.15.ls2: Identity()
vision_backbone.siglip_featurizer.blocks.15.drop_path2: Identity()
vision_backbone.siglip_featurizer.blocks.16: Block(
  (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1152, out_features=3456, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1152, out_features=1152, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): Identity()
  (drop_path1): Identity()
  (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1152, out_features=4304, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4304, out_features=1152, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): Identity()
  (drop_path2): Identity()
)
vision_backbone.siglip_featurizer.blocks.16.norm1: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.16.attn: Attention(
  (qkv): Linear(in_features=1152, out_features=3456, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1152, out_features=1152, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.16.attn.qkv: Linear(in_features=1152, out_features=3456, bias=True)
vision_backbone.siglip_featurizer.blocks.16.attn.q_norm: Identity()
vision_backbone.siglip_featurizer.blocks.16.attn.k_norm: Identity()
vision_backbone.siglip_featurizer.blocks.16.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.16.attn.proj: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.16.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.16.ls1: Identity()
vision_backbone.siglip_featurizer.blocks.16.drop_path1: Identity()
vision_backbone.siglip_featurizer.blocks.16.norm2: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.16.mlp: Mlp(
  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.16.mlp.fc1: Linear(in_features=1152, out_features=4304, bias=True)
vision_backbone.siglip_featurizer.blocks.16.mlp.act: GELU(approximate='none')
vision_backbone.siglip_featurizer.blocks.16.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.16.mlp.norm: Identity()
vision_backbone.siglip_featurizer.blocks.16.mlp.fc2: Linear(in_features=4304, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.16.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.16.ls2: Identity()
vision_backbone.siglip_featurizer.blocks.16.drop_path2: Identity()
vision_backbone.siglip_featurizer.blocks.17: Block(
  (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1152, out_features=3456, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1152, out_features=1152, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): Identity()
  (drop_path1): Identity()
  (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1152, out_features=4304, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4304, out_features=1152, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): Identity()
  (drop_path2): Identity()
)
vision_backbone.siglip_featurizer.blocks.17.norm1: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.17.attn: Attention(
  (qkv): Linear(in_features=1152, out_features=3456, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1152, out_features=1152, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.17.attn.qkv: Linear(in_features=1152, out_features=3456, bias=True)
vision_backbone.siglip_featurizer.blocks.17.attn.q_norm: Identity()
vision_backbone.siglip_featurizer.blocks.17.attn.k_norm: Identity()
vision_backbone.siglip_featurizer.blocks.17.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.17.attn.proj: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.17.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.17.ls1: Identity()
vision_backbone.siglip_featurizer.blocks.17.drop_path1: Identity()
vision_backbone.siglip_featurizer.blocks.17.norm2: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.17.mlp: Mlp(
  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.17.mlp.fc1: Linear(in_features=1152, out_features=4304, bias=True)
vision_backbone.siglip_featurizer.blocks.17.mlp.act: GELU(approximate='none')
vision_backbone.siglip_featurizer.blocks.17.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.17.mlp.norm: Identity()
vision_backbone.siglip_featurizer.blocks.17.mlp.fc2: Linear(in_features=4304, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.17.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.17.ls2: Identity()
vision_backbone.siglip_featurizer.blocks.17.drop_path2: Identity()
vision_backbone.siglip_featurizer.blocks.18: Block(
  (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1152, out_features=3456, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1152, out_features=1152, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): Identity()
  (drop_path1): Identity()
  (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1152, out_features=4304, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4304, out_features=1152, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): Identity()
  (drop_path2): Identity()
)
vision_backbone.siglip_featurizer.blocks.18.norm1: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.18.attn: Attention(
  (qkv): Linear(in_features=1152, out_features=3456, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1152, out_features=1152, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.18.attn.qkv: Linear(in_features=1152, out_features=3456, bias=True)
vision_backbone.siglip_featurizer.blocks.18.attn.q_norm: Identity()
vision_backbone.siglip_featurizer.blocks.18.attn.k_norm: Identity()
vision_backbone.siglip_featurizer.blocks.18.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.18.attn.proj: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.18.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.18.ls1: Identity()
vision_backbone.siglip_featurizer.blocks.18.drop_path1: Identity()
vision_backbone.siglip_featurizer.blocks.18.norm2: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.18.mlp: Mlp(
  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.18.mlp.fc1: Linear(in_features=1152, out_features=4304, bias=True)
vision_backbone.siglip_featurizer.blocks.18.mlp.act: GELU(approximate='none')
vision_backbone.siglip_featurizer.blocks.18.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.18.mlp.norm: Identity()
vision_backbone.siglip_featurizer.blocks.18.mlp.fc2: Linear(in_features=4304, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.18.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.18.ls2: Identity()
vision_backbone.siglip_featurizer.blocks.18.drop_path2: Identity()
vision_backbone.siglip_featurizer.blocks.19: Block(
  (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1152, out_features=3456, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1152, out_features=1152, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): Identity()
  (drop_path1): Identity()
  (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1152, out_features=4304, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4304, out_features=1152, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): Identity()
  (drop_path2): Identity()
)
vision_backbone.siglip_featurizer.blocks.19.norm1: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.19.attn: Attention(
  (qkv): Linear(in_features=1152, out_features=3456, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1152, out_features=1152, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.19.attn.qkv: Linear(in_features=1152, out_features=3456, bias=True)
vision_backbone.siglip_featurizer.blocks.19.attn.q_norm: Identity()
vision_backbone.siglip_featurizer.blocks.19.attn.k_norm: Identity()
vision_backbone.siglip_featurizer.blocks.19.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.19.attn.proj: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.19.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.19.ls1: Identity()
vision_backbone.siglip_featurizer.blocks.19.drop_path1: Identity()
vision_backbone.siglip_featurizer.blocks.19.norm2: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.19.mlp: Mlp(
  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.19.mlp.fc1: Linear(in_features=1152, out_features=4304, bias=True)
vision_backbone.siglip_featurizer.blocks.19.mlp.act: GELU(approximate='none')
vision_backbone.siglip_featurizer.blocks.19.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.19.mlp.norm: Identity()
vision_backbone.siglip_featurizer.blocks.19.mlp.fc2: Linear(in_features=4304, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.19.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.19.ls2: Identity()
vision_backbone.siglip_featurizer.blocks.19.drop_path2: Identity()
vision_backbone.siglip_featurizer.blocks.20: Block(
  (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1152, out_features=3456, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1152, out_features=1152, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): Identity()
  (drop_path1): Identity()
  (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1152, out_features=4304, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4304, out_features=1152, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): Identity()
  (drop_path2): Identity()
)
vision_backbone.siglip_featurizer.blocks.20.norm1: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.20.attn: Attention(
  (qkv): Linear(in_features=1152, out_features=3456, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1152, out_features=1152, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.20.attn.qkv: Linear(in_features=1152, out_features=3456, bias=True)
vision_backbone.siglip_featurizer.blocks.20.attn.q_norm: Identity()
vision_backbone.siglip_featurizer.blocks.20.attn.k_norm: Identity()
vision_backbone.siglip_featurizer.blocks.20.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.20.attn.proj: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.20.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.20.ls1: Identity()
vision_backbone.siglip_featurizer.blocks.20.drop_path1: Identity()
vision_backbone.siglip_featurizer.blocks.20.norm2: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.20.mlp: Mlp(
  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.20.mlp.fc1: Linear(in_features=1152, out_features=4304, bias=True)
vision_backbone.siglip_featurizer.blocks.20.mlp.act: GELU(approximate='none')
vision_backbone.siglip_featurizer.blocks.20.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.20.mlp.norm: Identity()
vision_backbone.siglip_featurizer.blocks.20.mlp.fc2: Linear(in_features=4304, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.20.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.20.ls2: Identity()
vision_backbone.siglip_featurizer.blocks.20.drop_path2: Identity()
vision_backbone.siglip_featurizer.blocks.21: Block(
  (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1152, out_features=3456, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1152, out_features=1152, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): Identity()
  (drop_path1): Identity()
  (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1152, out_features=4304, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4304, out_features=1152, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): Identity()
  (drop_path2): Identity()
)
vision_backbone.siglip_featurizer.blocks.21.norm1: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.21.attn: Attention(
  (qkv): Linear(in_features=1152, out_features=3456, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1152, out_features=1152, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.21.attn.qkv: Linear(in_features=1152, out_features=3456, bias=True)
vision_backbone.siglip_featurizer.blocks.21.attn.q_norm: Identity()
vision_backbone.siglip_featurizer.blocks.21.attn.k_norm: Identity()
vision_backbone.siglip_featurizer.blocks.21.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.21.attn.proj: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.21.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.21.ls1: Identity()
vision_backbone.siglip_featurizer.blocks.21.drop_path1: Identity()
vision_backbone.siglip_featurizer.blocks.21.norm2: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.21.mlp: Mlp(
  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.21.mlp.fc1: Linear(in_features=1152, out_features=4304, bias=True)
vision_backbone.siglip_featurizer.blocks.21.mlp.act: GELU(approximate='none')
vision_backbone.siglip_featurizer.blocks.21.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.21.mlp.norm: Identity()
vision_backbone.siglip_featurizer.blocks.21.mlp.fc2: Linear(in_features=4304, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.21.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.21.ls2: Identity()
vision_backbone.siglip_featurizer.blocks.21.drop_path2: Identity()
vision_backbone.siglip_featurizer.blocks.22: Block(
  (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1152, out_features=3456, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1152, out_features=1152, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): Identity()
  (drop_path1): Identity()
  (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1152, out_features=4304, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4304, out_features=1152, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): Identity()
  (drop_path2): Identity()
)
vision_backbone.siglip_featurizer.blocks.22.norm1: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.22.attn: Attention(
  (qkv): Linear(in_features=1152, out_features=3456, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1152, out_features=1152, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.22.attn.qkv: Linear(in_features=1152, out_features=3456, bias=True)
vision_backbone.siglip_featurizer.blocks.22.attn.q_norm: Identity()
vision_backbone.siglip_featurizer.blocks.22.attn.k_norm: Identity()
vision_backbone.siglip_featurizer.blocks.22.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.22.attn.proj: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.22.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.22.ls1: Identity()
vision_backbone.siglip_featurizer.blocks.22.drop_path1: Identity()
vision_backbone.siglip_featurizer.blocks.22.norm2: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.22.mlp: Mlp(
  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.22.mlp.fc1: Linear(in_features=1152, out_features=4304, bias=True)
vision_backbone.siglip_featurizer.blocks.22.mlp.act: GELU(approximate='none')
vision_backbone.siglip_featurizer.blocks.22.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.22.mlp.norm: Identity()
vision_backbone.siglip_featurizer.blocks.22.mlp.fc2: Linear(in_features=4304, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.22.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.22.ls2: Identity()
vision_backbone.siglip_featurizer.blocks.22.drop_path2: Identity()
vision_backbone.siglip_featurizer.blocks.23: Block(
  (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1152, out_features=3456, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1152, out_features=1152, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): Identity()
  (drop_path1): Identity()
  (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1152, out_features=4304, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4304, out_features=1152, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): Identity()
  (drop_path2): Identity()
)
vision_backbone.siglip_featurizer.blocks.23.norm1: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.23.attn: Attention(
  (qkv): Linear(in_features=1152, out_features=3456, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1152, out_features=1152, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.23.attn.qkv: Linear(in_features=1152, out_features=3456, bias=True)
vision_backbone.siglip_featurizer.blocks.23.attn.q_norm: Identity()
vision_backbone.siglip_featurizer.blocks.23.attn.k_norm: Identity()
vision_backbone.siglip_featurizer.blocks.23.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.23.attn.proj: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.23.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.23.ls1: Identity()
vision_backbone.siglip_featurizer.blocks.23.drop_path1: Identity()
vision_backbone.siglip_featurizer.blocks.23.norm2: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.23.mlp: Mlp(
  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.23.mlp.fc1: Linear(in_features=1152, out_features=4304, bias=True)
vision_backbone.siglip_featurizer.blocks.23.mlp.act: GELU(approximate='none')
vision_backbone.siglip_featurizer.blocks.23.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.23.mlp.norm: Identity()
vision_backbone.siglip_featurizer.blocks.23.mlp.fc2: Linear(in_features=4304, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.23.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.23.ls2: Identity()
vision_backbone.siglip_featurizer.blocks.23.drop_path2: Identity()
vision_backbone.siglip_featurizer.blocks.24: Block(
  (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1152, out_features=3456, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1152, out_features=1152, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): Identity()
  (drop_path1): Identity()
  (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1152, out_features=4304, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4304, out_features=1152, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): Identity()
  (drop_path2): Identity()
)
vision_backbone.siglip_featurizer.blocks.24.norm1: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.24.attn: Attention(
  (qkv): Linear(in_features=1152, out_features=3456, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1152, out_features=1152, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.24.attn.qkv: Linear(in_features=1152, out_features=3456, bias=True)
vision_backbone.siglip_featurizer.blocks.24.attn.q_norm: Identity()
vision_backbone.siglip_featurizer.blocks.24.attn.k_norm: Identity()
vision_backbone.siglip_featurizer.blocks.24.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.24.attn.proj: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.24.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.24.ls1: Identity()
vision_backbone.siglip_featurizer.blocks.24.drop_path1: Identity()
vision_backbone.siglip_featurizer.blocks.24.norm2: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.24.mlp: Mlp(
  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.24.mlp.fc1: Linear(in_features=1152, out_features=4304, bias=True)
vision_backbone.siglip_featurizer.blocks.24.mlp.act: GELU(approximate='none')
vision_backbone.siglip_featurizer.blocks.24.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.24.mlp.norm: Identity()
vision_backbone.siglip_featurizer.blocks.24.mlp.fc2: Linear(in_features=4304, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.24.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.24.ls2: Identity()
vision_backbone.siglip_featurizer.blocks.24.drop_path2: Identity()
vision_backbone.siglip_featurizer.blocks.25: Block(
  (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1152, out_features=3456, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1152, out_features=1152, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): Identity()
  (drop_path1): Identity()
  (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1152, out_features=4304, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4304, out_features=1152, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): Identity()
  (drop_path2): Identity()
)
vision_backbone.siglip_featurizer.blocks.25.norm1: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.25.attn: Attention(
  (qkv): Linear(in_features=1152, out_features=3456, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1152, out_features=1152, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.25.attn.qkv: Linear(in_features=1152, out_features=3456, bias=True)
vision_backbone.siglip_featurizer.blocks.25.attn.q_norm: Identity()
vision_backbone.siglip_featurizer.blocks.25.attn.k_norm: Identity()
vision_backbone.siglip_featurizer.blocks.25.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.25.attn.proj: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.25.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.25.ls1: Identity()
vision_backbone.siglip_featurizer.blocks.25.drop_path1: Identity()
vision_backbone.siglip_featurizer.blocks.25.norm2: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.25.mlp: Mlp(
  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.25.mlp.fc1: Linear(in_features=1152, out_features=4304, bias=True)
vision_backbone.siglip_featurizer.blocks.25.mlp.act: GELU(approximate='none')
vision_backbone.siglip_featurizer.blocks.25.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.25.mlp.norm: Identity()
vision_backbone.siglip_featurizer.blocks.25.mlp.fc2: Linear(in_features=4304, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.25.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.25.ls2: Identity()
vision_backbone.siglip_featurizer.blocks.25.drop_path2: Identity()
vision_backbone.siglip_featurizer.blocks.26: Block(
  (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (attn): Attention(
    (qkv): Linear(in_features=1152, out_features=3456, bias=True)
    (q_norm): Identity()
    (k_norm): Identity()
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1152, out_features=1152, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (ls1): Identity()
  (drop_path1): Identity()
  (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1152, out_features=4304, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4304, out_features=1152, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
  (ls2): Identity()
  (drop_path2): Identity()
)
vision_backbone.siglip_featurizer.blocks.26.norm1: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.26.attn: Attention(
  (qkv): Linear(in_features=1152, out_features=3456, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (attn_drop): Dropout(p=0.0, inplace=False)
  (proj): Linear(in_features=1152, out_features=1152, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.26.attn.qkv: Linear(in_features=1152, out_features=3456, bias=True)
vision_backbone.siglip_featurizer.blocks.26.attn.q_norm: Identity()
vision_backbone.siglip_featurizer.blocks.26.attn.k_norm: Identity()
vision_backbone.siglip_featurizer.blocks.26.attn.attn_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.26.attn.proj: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.26.attn.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.26.ls1: Identity()
vision_backbone.siglip_featurizer.blocks.26.drop_path1: Identity()
vision_backbone.siglip_featurizer.blocks.26.norm2: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.blocks.26.mlp: Mlp(
  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.blocks.26.mlp.fc1: Linear(in_features=1152, out_features=4304, bias=True)
vision_backbone.siglip_featurizer.blocks.26.mlp.act: GELU(approximate='none')
vision_backbone.siglip_featurizer.blocks.26.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.26.mlp.norm: Identity()
vision_backbone.siglip_featurizer.blocks.26.mlp.fc2: Linear(in_features=4304, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.blocks.26.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.blocks.26.ls2: Identity()
vision_backbone.siglip_featurizer.blocks.26.drop_path2: Identity()
vision_backbone.siglip_featurizer.norm: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.attn_pool: AttentionPoolLatent(
  (q): Linear(in_features=1152, out_features=1152, bias=True)
  (kv): Linear(in_features=1152, out_features=2304, bias=True)
  (q_norm): Identity()
  (k_norm): Identity()
  (proj): Linear(in_features=1152, out_features=1152, bias=True)
  (proj_drop): Dropout(p=0.0, inplace=False)
  (norm): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1152, out_features=4304, bias=True)
    (act): GELU(approximate='none')
    (drop1): Dropout(p=0.0, inplace=False)
    (norm): Identity()
    (fc2): Linear(in_features=4304, out_features=1152, bias=True)
    (drop2): Dropout(p=0.0, inplace=False)
  )
)
vision_backbone.siglip_featurizer.attn_pool.q: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.attn_pool.kv: Linear(in_features=1152, out_features=2304, bias=True)
vision_backbone.siglip_featurizer.attn_pool.q_norm: Identity()
vision_backbone.siglip_featurizer.attn_pool.k_norm: Identity()
vision_backbone.siglip_featurizer.attn_pool.proj: Linear(in_features=1152, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.attn_pool.proj_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.attn_pool.norm: LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
vision_backbone.siglip_featurizer.attn_pool.mlp: Mlp(
  (fc1): Linear(in_features=1152, out_features=4304, bias=True)
  (act): GELU(approximate='none')
  (drop1): Dropout(p=0.0, inplace=False)
  (norm): Identity()
  (fc2): Linear(in_features=4304, out_features=1152, bias=True)
  (drop2): Dropout(p=0.0, inplace=False)
)
vision_backbone.siglip_featurizer.attn_pool.mlp.fc1: Linear(in_features=1152, out_features=4304, bias=True)
vision_backbone.siglip_featurizer.attn_pool.mlp.act: GELU(approximate='none')
vision_backbone.siglip_featurizer.attn_pool.mlp.drop1: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.attn_pool.mlp.norm: Identity()
vision_backbone.siglip_featurizer.attn_pool.mlp.fc2: Linear(in_features=4304, out_features=1152, bias=True)
vision_backbone.siglip_featurizer.attn_pool.mlp.drop2: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.fc_norm: Identity()
vision_backbone.siglip_featurizer.head_drop: Dropout(p=0.0, inplace=False)
vision_backbone.siglip_featurizer.head: Identity()
llm_backbone: LLaMa2LLMBackbone(
  (llm): LlamaForCausalLM(
    (model): LlamaModel(
      (embed_tokens): Embedding(32064, 4096)
      (layers): ModuleList(
        (0-31): 32 x LlamaDecoderLayer(
          (self_attn): LlamaSdpaAttention(
            (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
            (rotary_emb): LlamaRotaryEmbedding()
          )
          (mlp): LlamaMLP(
            (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
            (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
            (act_fn): SiLU()
          )
          (input_layernorm): LlamaRMSNorm()
          (post_attention_layernorm): LlamaRMSNorm()
        )
      )
      (norm): LlamaRMSNorm()
    )
    (lm_head): Linear(in_features=4096, out_features=32064, bias=False)
  )
)
llm_backbone.llm: LlamaForCausalLM(
  (model): LlamaModel(
    (embed_tokens): Embedding(32064, 4096)
    (layers): ModuleList(
      (0-31): 32 x LlamaDecoderLayer(
        (self_attn): LlamaSdpaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (rotary_emb): LlamaRotaryEmbedding()
        )
        (mlp): LlamaMLP(
          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): LlamaRMSNorm()
        (post_attention_layernorm): LlamaRMSNorm()
      )
    )
    (norm): LlamaRMSNorm()
  )
  (lm_head): Linear(in_features=4096, out_features=32064, bias=False)
)
llm_backbone.llm.model: LlamaModel(
  (embed_tokens): Embedding(32064, 4096)
  (layers): ModuleList(
    (0-31): 32 x LlamaDecoderLayer(
      (self_attn): LlamaSdpaAttention(
        (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
        (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
        (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
        (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
        (rotary_emb): LlamaRotaryEmbedding()
      )
      (mlp): LlamaMLP(
        (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
        (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
        (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
        (act_fn): SiLU()
      )
      (input_layernorm): LlamaRMSNorm()
      (post_attention_layernorm): LlamaRMSNorm()
    )
  )
  (norm): LlamaRMSNorm()
)
llm_backbone.llm.model.embed_tokens: Embedding(32064, 4096)
llm_backbone.llm.model.layers: ModuleList(
  (0-31): 32 x LlamaDecoderLayer(
    (self_attn): LlamaSdpaAttention(
      (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
      (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
      (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
      (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
      (rotary_emb): LlamaRotaryEmbedding()
    )
    (mlp): LlamaMLP(
      (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
      (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
      (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
      (act_fn): SiLU()
    )
    (input_layernorm): LlamaRMSNorm()
    (post_attention_layernorm): LlamaRMSNorm()
  )
)
llm_backbone.llm.model.layers.0: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.0.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.0.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.0.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.0.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.0.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.0.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.0.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.0.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.0.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.0.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.0.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.0.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.0.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.1: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.1.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.1.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.1.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.1.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.1.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.1.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.1.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.1.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.1.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.1.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.1.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.1.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.1.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.2: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.2.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.2.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.2.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.2.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.2.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.2.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.2.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.2.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.2.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.2.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.2.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.2.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.2.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.3: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.3.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.3.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.3.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.3.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.3.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.3.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.3.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.3.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.3.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.3.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.3.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.3.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.3.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.4: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.4.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.4.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.4.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.4.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.4.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.4.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.4.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.4.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.4.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.4.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.4.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.4.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.4.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.5: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.5.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.5.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.5.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.5.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.5.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.5.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.5.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.5.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.5.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.5.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.5.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.5.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.5.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.6: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.6.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.6.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.6.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.6.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.6.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.6.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.6.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.6.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.6.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.6.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.6.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.6.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.6.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.7: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.7.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.7.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.7.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.7.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.7.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.7.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.7.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.7.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.7.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.7.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.7.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.7.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.7.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.8: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.8.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.8.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.8.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.8.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.8.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.8.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.8.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.8.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.8.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.8.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.8.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.8.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.8.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.9: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.9.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.9.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.9.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.9.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.9.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.9.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.9.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.9.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.9.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.9.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.9.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.9.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.9.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.10: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.10.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.10.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.10.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.10.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.10.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.10.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.10.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.10.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.10.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.10.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.10.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.10.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.10.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.11: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.11.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.11.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.11.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.11.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.11.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.11.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.11.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.11.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.11.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.11.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.11.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.11.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.11.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.12: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.12.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.12.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.12.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.12.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.12.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.12.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.12.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.12.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.12.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.12.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.12.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.12.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.12.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.13: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.13.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.13.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.13.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.13.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.13.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.13.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.13.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.13.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.13.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.13.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.13.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.13.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.13.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.14: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.14.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.14.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.14.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.14.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.14.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.14.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.14.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.14.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.14.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.14.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.14.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.14.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.14.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.15: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.15.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.15.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.15.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.15.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.15.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.15.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.15.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.15.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.15.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.15.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.15.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.15.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.15.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.16: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.16.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.16.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.16.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.16.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.16.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.16.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.16.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.16.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.16.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.16.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.16.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.16.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.16.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.17: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.17.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.17.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.17.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.17.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.17.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.17.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.17.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.17.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.17.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.17.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.17.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.17.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.17.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.18: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.18.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.18.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.18.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.18.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.18.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.18.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.18.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.18.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.18.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.18.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.18.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.18.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.18.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.19: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.19.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.19.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.19.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.19.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.19.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.19.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.19.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.19.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.19.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.19.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.19.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.19.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.19.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.20: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.20.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.20.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.20.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.20.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.20.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.20.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.20.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.20.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.20.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.20.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.20.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.20.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.20.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.21: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.21.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.21.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.21.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.21.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.21.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.21.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.21.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.21.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.21.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.21.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.21.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.21.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.21.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.22: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.22.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.22.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.22.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.22.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.22.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.22.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.22.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.22.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.22.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.22.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.22.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.22.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.22.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.23: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.23.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.23.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.23.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.23.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.23.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.23.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.23.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.23.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.23.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.23.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.23.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.23.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.23.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.24: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.24.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.24.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.24.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.24.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.24.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.24.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.24.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.24.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.24.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.24.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.24.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.24.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.24.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.25: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.25.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.25.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.25.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.25.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.25.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.25.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.25.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.25.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.25.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.25.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.25.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.25.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.25.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.26: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.26.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.26.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.26.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.26.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.26.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.26.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.26.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.26.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.26.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.26.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.26.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.26.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.26.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.27: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.27.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.27.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.27.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.27.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.27.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.27.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.27.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.27.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.27.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.27.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.27.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.27.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.27.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.28: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.28.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.28.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.28.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.28.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.28.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.28.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.28.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.28.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.28.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.28.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.28.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.28.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.28.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.29: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.29.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.29.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.29.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.29.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.29.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.29.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.29.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.29.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.29.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.29.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.29.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.29.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.29.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.30: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.30.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.30.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.30.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.30.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.30.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.30.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.30.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.30.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.30.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.30.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.30.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.30.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.30.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.31: LlamaDecoderLayer(
  (self_attn): LlamaSdpaAttention(
    (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (mlp): LlamaMLP(
    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
    (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
    (act_fn): SiLU()
  )
  (input_layernorm): LlamaRMSNorm()
  (post_attention_layernorm): LlamaRMSNorm()
)
llm_backbone.llm.model.layers.31.self_attn: LlamaSdpaAttention(
  (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (v_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
  (rotary_emb): LlamaRotaryEmbedding()
)
llm_backbone.llm.model.layers.31.self_attn.q_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.31.self_attn.k_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.31.self_attn.v_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.31.self_attn.o_proj: Linear(in_features=4096, out_features=4096, bias=False)
llm_backbone.llm.model.layers.31.self_attn.rotary_emb: LlamaRotaryEmbedding()
llm_backbone.llm.model.layers.31.mlp: LlamaMLP(
  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)
  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)
  (act_fn): SiLU()
)
llm_backbone.llm.model.layers.31.mlp.gate_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.31.mlp.up_proj: Linear(in_features=4096, out_features=11008, bias=False)
llm_backbone.llm.model.layers.31.mlp.down_proj: Linear(in_features=11008, out_features=4096, bias=False)
llm_backbone.llm.model.layers.31.mlp.act_fn: SiLU()
llm_backbone.llm.model.layers.31.input_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.layers.31.post_attention_layernorm: LlamaRMSNorm()
llm_backbone.llm.model.norm: LlamaRMSNorm()
llm_backbone.llm.lm_head: Linear(in_features=4096, out_features=32064, bias=False)
projector: FusedMLPProjector(
  (projector): Sequential(
    (0): Linear(in_features=2176, out_features=8704, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=8704, out_features=4096, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=4096, out_features=4096, bias=True)
  )
)
projector.projector: Sequential(
  (0): Linear(in_features=2176, out_features=8704, bias=True)
  (1): GELU(approximate='none')
  (2): Linear(in_features=8704, out_features=4096, bias=True)
  (3): GELU(approximate='none')
  (4): Linear(in_features=4096, out_features=4096, bias=True)
)
projector.projector.0: Linear(in_features=2176, out_features=8704, bias=True)
projector.projector.1: GELU(approximate='none')
projector.projector.2: Linear(in_features=8704, out_features=4096, bias=True)
projector.projector.3: GELU(approximate='none')
projector.projector.4: Linear(in_features=4096, out_features=4096, bias=True)
