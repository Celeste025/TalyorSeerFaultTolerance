Linear layers in model 'Octo':
==================================================
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.0.layer.0.SelfAttention.q - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.0.layer.0.SelfAttention.k - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.0.layer.0.SelfAttention.v - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.0.layer.0.SelfAttention.o - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.0.layer.1.DenseReluDense.wi - in_features=768, out_features=3072, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.0.layer.1.DenseReluDense.wo - in_features=3072, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.1.layer.0.SelfAttention.q - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.1.layer.0.SelfAttention.k - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.1.layer.0.SelfAttention.v - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.1.layer.0.SelfAttention.o - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.1.layer.1.DenseReluDense.wi - in_features=768, out_features=3072, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.1.layer.1.DenseReluDense.wo - in_features=3072, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.2.layer.0.SelfAttention.q - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.2.layer.0.SelfAttention.k - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.2.layer.0.SelfAttention.v - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.2.layer.0.SelfAttention.o - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.2.layer.1.DenseReluDense.wi - in_features=768, out_features=3072, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.2.layer.1.DenseReluDense.wo - in_features=3072, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.3.layer.0.SelfAttention.q - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.3.layer.0.SelfAttention.k - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.3.layer.0.SelfAttention.v - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.3.layer.0.SelfAttention.o - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.3.layer.1.DenseReluDense.wi - in_features=768, out_features=3072, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.3.layer.1.DenseReluDense.wo - in_features=3072, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.4.layer.0.SelfAttention.q - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.4.layer.0.SelfAttention.k - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.4.layer.0.SelfAttention.v - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.4.layer.0.SelfAttention.o - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.4.layer.1.DenseReluDense.wi - in_features=768, out_features=3072, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.4.layer.1.DenseReluDense.wo - in_features=3072, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.5.layer.0.SelfAttention.q - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.5.layer.0.SelfAttention.k - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.5.layer.0.SelfAttention.v - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.5.layer.0.SelfAttention.o - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.5.layer.1.DenseReluDense.wi - in_features=768, out_features=3072, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.5.layer.1.DenseReluDense.wo - in_features=3072, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.6.layer.0.SelfAttention.q - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.6.layer.0.SelfAttention.k - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.6.layer.0.SelfAttention.v - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.6.layer.0.SelfAttention.o - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.6.layer.1.DenseReluDense.wi - in_features=768, out_features=3072, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.6.layer.1.DenseReluDense.wo - in_features=3072, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.7.layer.0.SelfAttention.q - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.7.layer.0.SelfAttention.k - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.7.layer.0.SelfAttention.v - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.7.layer.0.SelfAttention.o - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.7.layer.1.DenseReluDense.wi - in_features=768, out_features=3072, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.7.layer.1.DenseReluDense.wo - in_features=3072, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.8.layer.0.SelfAttention.q - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.8.layer.0.SelfAttention.k - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.8.layer.0.SelfAttention.v - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.8.layer.0.SelfAttention.o - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.8.layer.1.DenseReluDense.wi - in_features=768, out_features=3072, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.8.layer.1.DenseReluDense.wo - in_features=3072, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.9.layer.0.SelfAttention.q - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.9.layer.0.SelfAttention.k - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.9.layer.0.SelfAttention.v - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.9.layer.0.SelfAttention.o - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.9.layer.1.DenseReluDense.wi - in_features=768, out_features=3072, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.9.layer.1.DenseReluDense.wo - in_features=3072, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.10.layer.0.SelfAttention.q - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.10.layer.0.SelfAttention.k - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.10.layer.0.SelfAttention.v - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.10.layer.0.SelfAttention.o - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.10.layer.1.DenseReluDense.wi - in_features=768, out_features=3072, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.10.layer.1.DenseReluDense.wo - in_features=3072, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.11.layer.0.SelfAttention.q - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.11.layer.0.SelfAttention.k - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.11.layer.0.SelfAttention.v - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.11.layer.0.SelfAttention.o - in_features=768, out_features=768, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.11.layer.1.DenseReluDense.wi - in_features=768, out_features=3072, bias=False
module.octo_transformer.task_tokenizers.language.hf_model.encoder.block.11.layer.1.DenseReluDense.wo - in_features=3072, out_features=768, bias=False
module.octo_transformer.block_transformer.transformer.encoder_blocks.0.self_attention.out_proj - in_features=768, out_features=768, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.0.mlp_block.dense1 - in_features=768, out_features=3072, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.0.mlp_block.dense2 - in_features=3072, out_features=768, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.1.self_attention.out_proj - in_features=768, out_features=768, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.1.mlp_block.dense1 - in_features=768, out_features=3072, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.1.mlp_block.dense2 - in_features=3072, out_features=768, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.2.self_attention.out_proj - in_features=768, out_features=768, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.2.mlp_block.dense1 - in_features=768, out_features=3072, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.2.mlp_block.dense2 - in_features=3072, out_features=768, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.3.self_attention.out_proj - in_features=768, out_features=768, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.3.mlp_block.dense1 - in_features=768, out_features=3072, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.3.mlp_block.dense2 - in_features=3072, out_features=768, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.4.self_attention.out_proj - in_features=768, out_features=768, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.4.mlp_block.dense1 - in_features=768, out_features=3072, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.4.mlp_block.dense2 - in_features=3072, out_features=768, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.5.self_attention.out_proj - in_features=768, out_features=768, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.5.mlp_block.dense1 - in_features=768, out_features=3072, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.5.mlp_block.dense2 - in_features=3072, out_features=768, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.6.self_attention.out_proj - in_features=768, out_features=768, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.6.mlp_block.dense1 - in_features=768, out_features=3072, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.6.mlp_block.dense2 - in_features=3072, out_features=768, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.7.self_attention.out_proj - in_features=768, out_features=768, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.7.mlp_block.dense1 - in_features=768, out_features=3072, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.7.mlp_block.dense2 - in_features=3072, out_features=768, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.8.self_attention.out_proj - in_features=768, out_features=768, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.8.mlp_block.dense1 - in_features=768, out_features=3072, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.8.mlp_block.dense2 - in_features=3072, out_features=768, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.9.self_attention.out_proj - in_features=768, out_features=768, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.9.mlp_block.dense1 - in_features=768, out_features=3072, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.9.mlp_block.dense2 - in_features=3072, out_features=768, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.10.self_attention.out_proj - in_features=768, out_features=768, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.10.mlp_block.dense1 - in_features=768, out_features=3072, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.10.mlp_block.dense2 - in_features=3072, out_features=768, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.11.self_attention.out_proj - in_features=768, out_features=768, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.11.mlp_block.dense1 - in_features=768, out_features=3072, bias=True
module.octo_transformer.block_transformer.transformer.encoder_blocks.11.mlp_block.dense2 - in_features=3072, out_features=768, bias=True
module.octo_transformer.task_projections.task_language_projection - in_features=768, out_features=768, bias=True
module.octo_transformer.obs_projections.obs_primary_projection - in_features=512, out_features=768, bias=True
module.octo_transformer.obs_projections.obs_wrist_projection - in_features=512, out_features=768, bias=True
module.heads.action.diffusion_model.cond_encoder.layers.0 - in_features=32, out_features=64, bias=True
module.heads.action.diffusion_model.cond_encoder.layers.2 - in_features=64, out_features=32, bias=True
module.heads.action.diffusion_model.reverse_network.linear1 - in_features=828, out_features=256, bias=True
module.heads.action.diffusion_model.reverse_network.blocks.0.linear1 - in_features=256, out_features=1024, bias=True
module.heads.action.diffusion_model.reverse_network.blocks.0.linear2 - in_features=1024, out_features=256, bias=True
module.heads.action.diffusion_model.reverse_network.blocks.1.linear1 - in_features=256, out_features=1024, bias=True
module.heads.action.diffusion_model.reverse_network.blocks.1.linear2 - in_features=1024, out_features=256, bias=True
module.heads.action.diffusion_model.reverse_network.blocks.2.linear1 - in_features=256, out_features=1024, bias=True
module.heads.action.diffusion_model.reverse_network.blocks.2.linear2 - in_features=1024, out_features=256, bias=True
module.heads.action.diffusion_model.reverse_network.linear2 - in_features=256, out_features=28, bias=True

==================================================
Total Linear layers: 121
