# import os
# import torch
# import numpy as np
# import matplotlib.pyplot as plt
# import pandas as pd
# import gc
# from tqdm import tqdm

# # ====== å‚æ•°é…ç½® ======
# records_dir = "/data/home/jinqiwen/workspace/diffusion_fault_tolerance/TaylorSeerFaultTolerance/TaylorSeers-Diffusers/taylorseer_flux/results/Debug2_target_Skip_step_50_err_prob_0.0_h/images_gen/layer_inout"
# save_dir = os.path.join(os.path.dirname(records_dir), "analysis_results")
# print(save_dir)
# os.makedirs(save_dir, exist_ok=True)

# # ====== è·å– step æ–‡ä»¶ ======
# files = sorted([f for f in os.listdir(records_dir) if f.endswith(".pt")])
# print(f"æ‰¾åˆ° {len(files)} ä¸ªæ­¥éª¤æ–‡ä»¶")

# if len(files) < 2:
#     raise ValueError("è‡³å°‘éœ€è¦2ä¸ªstepæ‰èƒ½è®¡ç®—å˜åŒ–è¶‹åŠ¿ã€‚")

# # ====== åˆå§‹åŒ– ======
# prev_data = torch.load(os.path.join(records_dir, files[0]), map_location="cpu")
# layer_names = list(prev_data.keys())
# l1_diffs = {layer: [] for layer in layer_names}

# # ====== æµå¼åˆ†æç›¸é‚» step çš„ L1 è¾“å‡ºå˜åŒ– ======
# for i in tqdm(range(len(files) - 1), desc="Processing steps"):
#     path_next = os.path.join(records_dir, files[i + 1])
#     next_data = torch.load(path_next, map_location="cpu")

#     for layer in layer_names:
#         if layer not in prev_data or layer not in next_data:
#             l1_diffs[layer].append(np.nan)
#             continue

#         out_t = prev_data[layer].get("output", None)
#         out_t1 = next_data[layer].get("output", None)

#         if out_t is None or out_t1 is None:
#             l1_diffs[layer].append(np.nan)
#             continue

#         # å¦‚æœ output æ˜¯ tupleï¼Œå–ç¬¬ä¸€ä¸ª tensor
#         if isinstance(out_t, tuple): out_t = out_t[0]
#         if isinstance(out_t1, tuple): out_t1 = out_t1[0]

#         if not (isinstance(out_t, torch.Tensor) and isinstance(out_t1, torch.Tensor)):
#             l1_diffs[layer].append(np.nan)
#             continue
#         if out_t.shape != out_t1.shape:
#             l1_diffs[layer].append(np.nan)
#             continue

#         diff = torch.mean(torch.abs(out_t - out_t1)).item()
#         l1_diffs[layer].append(diff)

#     if (i + 1) % 5 == 0 or i == len(files) - 2:
#         example_layer = layer_names[0]
#         print(f"[Step {i+1}/{len(files)-1}] ç¤ºä¾‹å±‚ '{example_layer}' å½“å‰ L1: {l1_diffs[example_layer][-1]:.6f}")

#     # é‡Šæ”¾å†…å­˜
#     del prev_data
#     gc.collect()
#     torch.cuda.empty_cache()

#     prev_data = next_data

# # ====== âœ… ä¿å­˜ç»“æœä¸º CSV ======
# df = pd.DataFrame(l1_diffs)
# df.index = [f"step_{i}" for i in range(len(df))]
# csv_path = os.path.join(save_dir, "layer_l1_diffs.csv")
# df.to_csv(csv_path)
# print(f"âœ… å·²ä¿å­˜å±‚è¾“å‡ºå˜åŒ–ç»“æœåˆ°: {csv_path}")

# # ===================================================
# # ============== ç»˜å›¾å‡½æ•°å°è£… =======================
# # ===================================================

# def plot_layer_trends(df, save_dir, group_size=10):
#     num_layers = len(df.columns)
#     num_groups = (num_layers + group_size - 1) // group_size

#     for g in range(num_groups):
#         start = g * group_size
#         end = min((g + 1) * group_size, num_layers)
#         sub_layers = df.columns[start:end]

#         plt.figure(figsize=(10, 5))
#         for layer in sub_layers:
#             plt.plot(df.index, df[layer], label=layer, alpha=0.7, linewidth=0.8)
#         plt.xlabel("Step")
#         plt.ylabel("Mean L1 Change (output)")
#         plt.title(f"Layer Output Change vs Step (Layers {start}â€“{end-1})")
#         plt.legend(fontsize=7, bbox_to_anchor=(1.05, 1), loc="upper left")
#         plt.tight_layout()
#         out_path = os.path.join(save_dir, f"layer_l1_trends_part{g+1}.png")
#         plt.savefig(out_path, dpi=300)
#         plt.close()
#         print(f"ğŸ“ˆ å­å›¾å·²ä¿å­˜: {out_path}")

# def plot_layer_correlation(df, save_dir):
#     corr = df.corr(method="pearson")
#     plt.figure(figsize=(10, 8))
#     plt.imshow(corr, cmap="coolwarm", interpolation="nearest")
#     plt.colorbar(label="Pearson Corr")
#     plt.title("Layer Dynamics Correlation")
#     plt.xticks(range(len(corr.columns)), corr.columns, rotation=90, fontsize=6)
#     plt.yticks(range(len(corr.index)), corr.index, fontsize=6)
#     plt.tight_layout()
#     out_path = os.path.join(save_dir, "layer_correlation_heatmap.png")
#     plt.savefig(out_path, dpi=300)
#     plt.close()
#     print(f"ğŸ”¥ å±‚é—´ç›¸å…³æ€§çƒ­åŠ›å›¾å·²ä¿å­˜: {out_path}")

# # ===================================================
# # ============== è°ƒç”¨ç»˜å›¾å‡½æ•° =======================
# # ===================================================
# plot_layer_trends(df, save_dir, group_size=10)
# plot_layer_correlation(df, save_dir)



import os
import torch
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import gc
from tqdm import tqdm

# ====== å‚æ•°é…ç½® ======
records_dir = "/data/home/jinqiwen/workspace/diffusion_fault_tolerance/TaylorSeerFaultTolerance/TaylorSeers-Diffusers/taylorseer_flux/results/Debug2_target_Skip_step_50_err_prob_0.0_h/images_gen/layer_inout"
save_dir = os.path.join(os.path.dirname(records_dir), "analysis_results")
print(save_dir)
os.makedirs(save_dir, exist_ok=True)

# ====== æŒ‡å®šè¦åˆ†æçš„å±‚åç§° ======
target_layer = "transformer_blocks.13"  # è¯·æ›¿æ¢ä¸ºå®é™…çš„å±‚åç§°

# ====== è·å– step æ–‡ä»¶ ======
files = sorted([f for f in os.listdir(records_dir) if f.endswith(".pt")])
print(f"æ‰¾åˆ° {len(files)} ä¸ªæ­¥éª¤æ–‡ä»¶")

if len(files) == 0:
    raise ValueError("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ­¥éª¤æ–‡ä»¶ã€‚")

def get_layer_tensor(layer_name, step_files, records_dir, max_steps=None):
    """
    æµå¼è¯»å–æŒ‡å®šå±‚çš„è¾“å‡ºtensor
    
    Args:
        layer_name: ç›®æ ‡å±‚åç§°
        step_files: æ­¥éª¤æ–‡ä»¶åˆ—è¡¨
        records_dir: è®°å½•æ–‡ä»¶ç›®å½•
        max_steps: æœ€å¤§æ­¥éª¤æ•°ï¼ˆç”¨äºé™åˆ¶å†…å­˜ä½¿ç”¨ï¼‰
    
    Returns:
        tensors: å„æ­¥éª¤çš„tensoråˆ—è¡¨
        valid_steps: æœ‰æ•ˆçš„æ­¥éª¤ç´¢å¼•åˆ—è¡¨
    """
    tensors = []
    valid_steps = []
    
    if max_steps is None:
        max_steps = len(step_files)
    
    for i in tqdm(range(min(len(step_files), max_steps)), desc=f"è¯»å–å±‚ '{layer_name}' æ•°æ®"):
        file_path = os.path.join(records_dir, step_files[i])
        try:
            data = torch.load(file_path, map_location="cpu")
            if layer_name not in data:
                print(f"è­¦å‘Š: æ­¥éª¤ {i} ä¸­æœªæ‰¾åˆ°å±‚ '{layer_name}'")
                continue
                
            layer_data = data[layer_name]
            output_tensor = layer_data.get("output", None)
            
            if output_tensor is None:
                print(f"è­¦å‘Š: æ­¥éª¤ {i} ä¸­å±‚ '{layer_name}' æ²¡æœ‰è¾“å‡º")
                continue
                
            # å¦‚æœ output æ˜¯ tupleï¼Œå–ç¬¬ä¸€ä¸ª tensor
            if isinstance(output_tensor, tuple):
                output_tensor = output_tensor[0]
            
            if not isinstance(output_tensor, torch.Tensor):
                print(f"è­¦å‘Š: æ­¥éª¤ {i} çš„è¾“å‡ºä¸æ˜¯tensor")
                continue
            
            # å¦‚æœç»´åº¦å¤§äº2ï¼Œå»æ‰ç¬¬ä¸€ç»´ï¼ˆé€šå¸¸æ˜¯batchç»´åº¦ï¼‰
            if output_tensor.dim() > 2:
                output_tensor = output_tensor[0]  # å–batchä¸­çš„ç¬¬ä¸€ä¸ªæ ·æœ¬
            
            tensors.append(output_tensor.detach().cpu())
            valid_steps.append(i)
            
            # é‡Šæ”¾å†…å­˜
            del data
            gc.collect()
            torch.cuda.empty_cache()
            
        except Exception as e:
            print(f"é”™è¯¯: è¯»å–æ­¥éª¤ {i} æ—¶å‡ºé”™: {e}")
            continue
    
    return tensors, valid_steps

def plot_tensor_heatmaps(tensors, valid_steps, save_path, max_plots=20, vmin=None, vmax=None, 
                        region=None):
    """
    ç»˜åˆ¶æ¯ä¸ªæ­¥éª¤tensorçš„çƒ­å›¾ï¼Œå¯æ‰‹åŠ¨è®¾ç½®ä¸Šä¸‹é™å¹¶ç»Ÿè®¡è¶…å‡ºèŒƒå›´çš„æ•°é‡ï¼Œæ”¯æŒåŒºåŸŸé€‰æ‹©
    
    Args:
        tensors: å„æ­¥éª¤çš„tensoråˆ—è¡¨
        valid_steps: æœ‰æ•ˆçš„æ­¥éª¤ç´¢å¼•åˆ—è¡¨
        save_path: ä¿å­˜è·¯å¾„
        max_plots: æœ€å¤§ç»˜å›¾æ•°é‡
        vmin: é¢œè‰²æ˜ å°„ä¸‹é™
        vmax: é¢œè‰²æ˜ å°„ä¸Šé™
        region: åŒºåŸŸé€‰æ‹©ï¼Œæ ¼å¼ä¸º (x_start, y_start, dx, dy)
                å¦‚æœä¸ºNoneï¼Œåˆ™ç»˜åˆ¶æ•´ä¸ªtensor
    """
    if not tensors:
        print("æ²¡æœ‰å¯ç”¨çš„tensoræ•°æ®")
        return
    
    # æ£€æŸ¥ç¬¬ä¸€ä¸ªtensorçš„å½¢çŠ¶
    base_tensor = tensors[0]
    print(f"åŸå§‹tensorå½¢çŠ¶: {base_tensor.shape}")
    
    # å¤„ç†åŒºåŸŸé€‰æ‹©
    if region is not None:
        x_start, y_start, dx, dy = region
        x_end = x_start + dx
        y_end = y_start + dy
        
        # éªŒè¯åŒºåŸŸæ˜¯å¦æœ‰æ•ˆ
        if x_start < 0 or y_start < 0 or x_end > base_tensor.shape[0] or y_end > base_tensor.shape[1]:
            print(f"è­¦å‘Š: åŒºåŸŸ {region} è¶…å‡ºtensorèŒƒå›´ {base_tensor.shape}")
            # è‡ªåŠ¨è°ƒæ•´åˆ°æœ‰æ•ˆèŒƒå›´
            x_start = max(0, x_start)
            y_start = max(0, y_start)
            x_end = min(base_tensor.shape[0], x_end)
            y_end = min(base_tensor.shape[1], y_end)
            dx = x_end - x_start
            dy = y_end - y_start
            print(f"å·²è°ƒæ•´åŒºåŸŸä¸º: ({x_start}, {y_start}, {dx}, {dy})")
        
        print(f"åˆ†æåŒºåŸŸ: [{x_start}:{x_end}, {y_start}:{y_end}]")
    else:
        print("åˆ†ææ•´ä¸ªtensor")
    
    # æå–åŒºåŸŸæ•°æ®ç”¨äºèŒƒå›´è®¡ç®—
    if region is not None:
        region_tensors = []
        for tensor in tensors:
            if tensor.dim() == 2:
                region_tensor = tensor[x_start:x_end, y_start:y_end]
            else:
                # å¯¹äºé2D tensorï¼Œå…ˆreshapeå†åˆ‡ç‰‡
                tensor_2d = tensor.view(tensor.size(0), -1)
                region_tensor = tensor_2d[x_start:x_end, y_start:y_end]
            region_tensors.append(region_tensor)
        
        # ä½¿ç”¨åŒºåŸŸæ•°æ®è®¡ç®—èŒƒå›´
        all_values = torch.cat([t.flatten() for t in region_tensors])
    else:
        all_values = torch.cat([t.flatten() for t in tensors])
    
    # å¦‚æœæ²¡æœ‰æ‰‹åŠ¨è®¾ç½®ä¸Šä¸‹é™ï¼Œè‡ªåŠ¨è®¡ç®—åˆç†çš„èŒƒå›´
    if vmin is None or vmax is None:
        auto_vmin = all_values.quantile(0.01).item()  # 1%åˆ†ä½æ•°
        auto_vmax = all_values.quantile(0.99).item()  # 99%åˆ†ä½æ•°
        
        if vmin is None:
            vmin = auto_vmin
        if vmax is None:
            vmax = auto_vmax
        
        print(f"è‡ªåŠ¨è®¡ç®—çš„é¢œè‰²èŒƒå›´: [{vmin:.2f}, {vmax:.2f}]")
    
    # é™åˆ¶ç»˜å›¾æ•°é‡ä»¥é¿å…å†…å­˜é—®é¢˜
    plot_indices = np.linspace(0, len(tensors)-1, min(len(tensors), max_plots), dtype=int)
    
    n_rows = int(np.ceil(len(plot_indices) / 5))
    n_cols = min(5, len(plot_indices))
    
    fig, axes = plt.subplots(n_rows, n_cols, figsize=(5*n_cols, 4*n_rows))
    if n_rows == 1 and n_cols == 1:
        axes = np.array([axes])
    elif n_rows > 1 and n_cols > 1:
        axes = axes.flatten()
    
    # ç»Ÿè®¡æ€»ä½“ä¿¡æ¯
    total_out_of_range_stats = {
        'below': 0, 'above': 0, 'total_elements': 0
    }
    
    for idx, (ax, tensor_idx) in enumerate(zip(axes, plot_indices)):
        tensor = tensors[tensor_idx]
        step = valid_steps[tensor_idx]
        
        # å¤„ç†tensorå½¢çŠ¶å’ŒåŒºåŸŸé€‰æ‹©
        if tensor.dim() == 1:
            size = tensor.size(0)
            factors = [i for i in range(1, int(np.sqrt(size)) + 1) if size % i == 0]
            if factors:
                h = factors[-1]
                w = size // h
                tensor_2d = tensor.reshape(h, w)
            else:
                h = int(np.sqrt(size))
                w = int(np.ceil(size / h))
                tensor_2d = tensor[:h*w].reshape(h, w)
        elif tensor.dim() == 2:
            tensor_2d = tensor
        else:
            tensor_2d = tensor.view(tensor.size(0), -1)
        
        # åº”ç”¨åŒºåŸŸé€‰æ‹©
        if region is not None:
            tensor_2d = tensor_2d[x_start:x_end, y_start:y_end]
        
        tensor_np = tensor_2d.numpy()
        flat_tensor = tensor_np.flatten()
        
        # ç»Ÿè®¡è¶…å‡ºèŒƒå›´çš„æ•°é‡
        below_count = np.sum(flat_tensor < vmin)
        above_count = np.sum(flat_tensor > vmax)
        total_elements = flat_tensor.size
        
        # æ›´æ–°æ€»ä½“ç»Ÿè®¡
        total_out_of_range_stats['below'] += below_count
        total_out_of_range_stats['above'] += above_count
        total_out_of_range_stats['total_elements'] += total_elements
        
        below_percent = (below_count / total_elements) * 100
        above_percent = (above_count / total_elements) * 100
        
        # ç»˜åˆ¶çƒ­å›¾
        im = ax.imshow(tensor_np, cmap='viridis', aspect='auto', vmin=vmin, vmax=vmax)
        
        # æ·»åŠ é¢œè‰²æ¡
        plt.colorbar(im, ax=ax, shrink=0.8)
        
        # è®¾ç½®æ ‡é¢˜å’Œç»Ÿè®¡ä¿¡æ¯
        if region is not None:
            title = f'Step {step}\nRegion: [{x_start}:{x_end}, {y_start}:{y_end}]'
        else:
            title = f'Step {step}\nShape: {tensor_2d.shape}'
        ax.set_title(title, fontsize=10)
        
        # åœ¨å­å›¾æ—è¾¹æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        stats_text = (f'Range: [{vmin:.1f}, {vmax:.1f}]\n'
                     f'Below: {below_count} ({below_percent:.1f}%)\n'
                     f'Above: {above_count} ({above_percent:.1f}%)\n'
                     f'Min: {flat_tensor.min():.1f}\n'
                     f'Max: {flat_tensor.max():.1f}')
        
        # åœ¨å­å›¾å³ä¾§æ·»åŠ æ–‡æœ¬
        ax.text(1.05, 0.5, stats_text, transform=ax.transAxes, fontsize=8,
               verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
    
    # éšè—å¤šä½™çš„å­å›¾
    for idx in range(len(plot_indices), len(axes)):
        axes[idx].set_visible(False)
    
    # æ·»åŠ æ€»ä½“ç»Ÿè®¡ä¿¡æ¯
    total_below_percent = (total_out_of_range_stats['below'] / total_out_of_range_stats['total_elements']) * 100
    total_above_percent = (total_out_of_range_stats['above'] / total_out_of_range_stats['total_elements']) * 100
    
    overall_stats = (f'Overall Statistics:\n'
                    f'Total elements: {total_out_of_range_stats["total_elements"]:,}\n'
                    f'Below {vmin}: {total_out_of_range_stats["below"]:,} ({total_below_percent:.2f}%)\n'
                    f'Above {vmax}: {total_out_of_range_stats["above"]:,} ({total_above_percent:.2f}%)\n'
                    f'In range: {total_out_of_range_stats["total_elements"] - total_out_of_range_stats["below"] - total_out_of_range_stats["above"]:,} '
                    f'({100 - total_below_percent - total_above_percent:.2f}%)')
    
    plt.figtext(0.02, 0.02, overall_stats, fontsize=9, 
                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))
    
    # è®¾ç½®æ€»æ ‡é¢˜
    if region is not None:
        plt.suptitle(f'Tensor Heatmaps for Layer: {target_layer} (Region: [{x_start}:{x_end}, {y_start}:{y_end}])')
    else:
        plt.suptitle(f'Tensor Heatmaps for Layer: {target_layer} (Full Tensor)')
    
    plt.tight_layout()
    plt.subplots_adjust(bottom=0.1)  # ä¸ºæ€»ä½“ç»Ÿè®¡ç•™å‡ºç©ºé—´
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"çƒ­å›¾å·²ä¿å­˜: {save_path}")
    print(f"æ€»ä½“è¶…å‡ºèŒƒå›´ç»Ÿè®¡: {overall_stats}")

# è¾…åŠ©å‡½æ•°ï¼šè‡ªåŠ¨å¯»æ‰¾æœ‰è¶£åŒºåŸŸ
def find_interesting_regions(tensors, region_size=(100, 100), num_regions=5):
    """
    è‡ªåŠ¨å¯»æ‰¾æ•°å€¼å˜åŒ–è¾ƒå¤§çš„æœ‰è¶£åŒºåŸŸ
    
    Args:
        tensors: tensoråˆ—è¡¨
        region_size: åŒºåŸŸå¤§å° (height, width)
        num_regions: è¿”å›çš„åŒºåŸŸæ•°é‡
    """
    if not tensors:
        return []
    
    # ä½¿ç”¨ç¬¬ä¸€ä¸ªtensorä½œä¸ºå‚è€ƒ
    base_tensor = tensors[0]
    if base_tensor.dim() != 2:
        base_tensor = base_tensor.view(base_tensor.size(0), -1)
    
    h, w = base_tensor.shape
    region_h, region_w = region_size
    
    # è®¡ç®—æ¯ä¸ªåŒºåŸŸçš„æ–¹å·®ï¼ˆå˜åŒ–ç¨‹åº¦ï¼‰
    regions_variance = []
    
    for i in range(0, h - region_h, region_h // 2):
        for j in range(0, w - region_w, region_w // 2):
            region_variances = []
            for tensor in tensors[:10]:  # åªæ£€æŸ¥å‰10ä¸ªæ­¥éª¤ä»¥å‡å°‘è®¡ç®—é‡
                if tensor.dim() != 2:
                    tensor_2d = tensor.view(tensor.size(0), -1)
                else:
                    tensor_2d = tensor
                
                region = tensor_2d[i:i+region_h, j:j+region_w]
                region_variances.append(region.var().item())
            
            # ä½¿ç”¨å¹³å‡æ–¹å·®ä½œä¸ºå…´è¶£åº¦æŒ‡æ ‡
            avg_variance = np.mean(region_variances)
            regions_variance.append((i, j, avg_variance))
    
    # æŒ‰æ–¹å·®æ’åºï¼Œé€‰æ‹©æœ€æœ‰è¶£çš„åŒºåŸŸ
    regions_variance.sort(key=lambda x: x[2], reverse=True)
    
    interesting_regions = []
    for i, j, variance in regions_variance[:num_regions]:
        interesting_regions.append({
            'coords': (i, j, region_h, region_w),
            'variance': variance
        })
        print(f"åŒºåŸŸ [{i}:{i+region_h}, {j}:{j+region_w}] - å¹³å‡æ–¹å·®: {variance:.4f}")
    
    return interesting_regions

def plot_random_points_trend(tensors, valid_steps, save_path, n_points=10):
    """
    éšæœºé€‰æ‹©nä¸ªç‚¹ï¼Œè§‚å¯Ÿå…¶å€¼åœ¨æ­¥éª¤é—´çš„å˜åŒ–
    
    Args:
        tensors: å„æ­¥éª¤çš„tensoråˆ—è¡¨
        valid_steps: æœ‰æ•ˆçš„æ­¥éª¤ç´¢å¼•åˆ—è¡¨
        save_path: ä¿å­˜è·¯å¾„
        n_points: è¦è·Ÿè¸ªçš„ç‚¹æ•°
    """
    if not tensors:
        print("æ²¡æœ‰å¯ç”¨çš„tensoræ•°æ®")
        return
    
    # æ‰¾åˆ°æ‰€æœ‰tensorçš„å…±åŒå½¢çŠ¶ï¼ˆå–ç¬¬ä¸€ä¸ªtensorçš„å½¢çŠ¶ï¼‰
    base_tensor = tensors[0]
    
    # è®¡ç®—æ€»å…ƒç´ æ•°
    total_elements = base_tensor.numel()
    
    # éšæœºé€‰æ‹©ç‚¹
    if total_elements <= n_points:
        # å¦‚æœå…ƒç´ æ•°å°‘äºn_pointsï¼Œé€‰æ‹©æ‰€æœ‰ç‚¹
        selected_indices = list(range(total_elements))
        n_points = total_elements
    else:
        selected_indices = np.random.choice(total_elements, n_points, replace=False)
    
    # è·å–æ¯ä¸ªç‚¹çš„åæ ‡ï¼ˆç”¨äºå›¾ä¾‹ï¼‰
    coordinates = []
    for idx in selected_indices:
        if base_tensor.dim() == 1:
            coord = f"[{idx}]"
        else:
            # å°†çº¿æ€§ç´¢å¼•è½¬æ¢ä¸ºå¤šç»´ç´¢å¼•
            coord = np.unravel_index(idx, base_tensor.shape)
            coord_str = "[" + ",".join(map(str, coord)) + "]"
            coordinates.append(coord_str)
    
    # æ”¶é›†æ¯ä¸ªç‚¹åœ¨æ‰€æœ‰æ­¥éª¤çš„å€¼
    point_values = np.zeros((n_points, len(tensors)))
    
    for step_idx, tensor in enumerate(tensors):
        flat_tensor = tensor.flatten()
        for point_idx, linear_idx in enumerate(selected_indices):
            if linear_idx < len(flat_tensor):
                point_values[point_idx, step_idx] = flat_tensor[linear_idx].item()
    
    # ç»˜åˆ¶è¶‹åŠ¿å›¾
    plt.figure(figsize=(12, 6))
    
    for point_idx in range(n_points):
        plt.plot(valid_steps, point_values[point_idx, :], 
                marker='o', markersize=2, linewidth=1, 
                label=f'Point {coordinates[point_idx]}' if coordinates else f'Point {selected_indices[point_idx]}')
    
    plt.xlabel('Step')
    plt.ylabel('Value')
    plt.title(f'Random Points Value Trends for Layer: {target_layer}')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"ç‚¹è¶‹åŠ¿å›¾å·²ä¿å­˜: {save_path}")
    
    # å¯é€‰ï¼šä¿å­˜æ•°æ®åˆ°CSV
    trend_data = pd.DataFrame(point_values.T, index=valid_steps, 
                             columns=[f'Point_{i}' for i in range(n_points)])
    csv_path = save_path.replace('.png', '.csv')
    trend_data.to_csv(csv_path)
    print(f"ç‚¹è¶‹åŠ¿æ•°æ®å·²ä¿å­˜: {csv_path}")

# ====== ä¸»æ‰§è¡Œæµç¨‹ ======
if __name__ == "__main__":
    # 1. è¯»å–æŒ‡å®šå±‚çš„tensoræ•°æ®ï¼ˆé™åˆ¶æœ€å¤§æ­¥éª¤æ•°ä»¥é¿å…å†…å­˜é—®é¢˜ï¼‰
    print(f"å¼€å§‹åˆ†æå±‚: {target_layer}")
    max_steps = 50  # å¯æ ¹æ®éœ€è¦è°ƒæ•´ï¼Œæˆ–è®¾ä¸ºNoneè¯»å–æ‰€æœ‰æ­¥éª¤
    
    tensors, valid_steps = get_layer_tensor(target_layer, files, records_dir, max_steps)
    
    if not tensors:
        print(f"é”™è¯¯: æœªèƒ½è¯»å–åˆ°å±‚ '{target_layer}' çš„ä»»ä½•æœ‰æ•ˆæ•°æ®")
        exit(1)
    
    print(f"æˆåŠŸè¯»å– {len(tensors)} ä¸ªæ­¥éª¤çš„æ•°æ®")
    print(f"Tensorå½¢çŠ¶ç¤ºä¾‹: {tensors[0].shape}")
    
    # 2. ç»˜åˆ¶çƒ­å›¾
    heatmap_path = os.path.join(save_dir, f"{target_layer}_heatmaps.png")
    plot_tensor_heatmaps(tensors, valid_steps, heatmap_path, max_plots=25, vmin=-200, vmax=200, region=(0,0,200,200))
    
    # 3. ç»˜åˆ¶éšæœºç‚¹è¶‹åŠ¿å›¾
    trend_path = os.path.join(save_dir, f"{target_layer}_point_trends.png")
    plot_random_points_trend(tensors, valid_steps, trend_path, n_points=25)
    
    # 4. æ¸…ç†å†…å­˜
    del tensors
    gc.collect()
    torch.cuda.empty_cache()
    
    print("åˆ†æå®Œæˆï¼")